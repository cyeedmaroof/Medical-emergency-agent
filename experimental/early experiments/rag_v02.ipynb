{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_azure_openai_model, get_azure_openai_chat_model, create_vector_store\n",
    "\n",
    "model1 = get_azure_openai_model()\n",
    "model2 = get_azure_openai_chat_model()\n",
    "vector_store = create_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDFs\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "folder_path = \"papers\"\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "pages = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(os.path.join(folder_path, pdf_file))\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add docs to vector store\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=pages)\n",
    "\n",
    "# Retrival\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment with query construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# output parsers\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompts\n",
    "from langchain_core.prompts import (\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to understand and generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | model2 \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Queries:\n",
      "What does deep learning refer to in the context of artificial intelligence?  \n",
      "Can you explain the concept of deep learning and its applications?  \n",
      "What are the key principles and techniques involved in deep learning?  \n",
      "How does deep learning differ from traditional machine learning methods?  \n",
      "What are some examples of deep learning in practice today?  \n",
      "10\n",
      "Page 42: 21Summary\n",
      "generative adversarial networks, evolutionary methods, meta-learning, and transfer\n",
      "learning. Again, this is all in line with our skills-focused mode of teaching, so the par-\n",
      "ticulars of these advances is not what’s important.\n",
      "Summary\n",
      " Reinforcement learning is a subclass of machine learni\n",
      "\n",
      "Page 24: 3\n",
      "What is reinforcement\n",
      "learning?\n",
      "Computer languages of the future will be more concerned with goals and less with\n",
      "procedures specified by the programmer.\n",
      "—Marvin Minksy, 1970 ACM Turing Lecture\n",
      "If you’re reading this book, you are probably familiar with how deep neural net-\n",
      "works are used for thing\n",
      "\n",
      "Page 306: 285Machine learning interpretability with attention and relational biases\n",
      "representation of the features within the image. In a sense, we hope the SAM will con-\n",
      "vert a raw image into a graph structure, and that the graph structure it constructs will\n",
      "be somewhat interpretable. If we train a SAM on a \n",
      "\n",
      "Page 25: 4 CHAPTER 1 What is reinforcement learning?\n",
      "1.1 The “deep” in deep reinforcement learning\n",
      "Deep learning models are just one of many kinds of machine learning models we\n",
      "can use to classify images. In general, we just need some sort of function that takes\n",
      "in an image and returns a class label (in this\n",
      "\n",
      "Page 14: xiii\n",
      "preface\n",
      "Deep reinforcement learning was launched into the spotlight in 2015, when Deep-\n",
      "Mind produced an algorithm capable of playing a suite of Atari 2600 games at super-\n",
      "human performance. Artificial intelligence seemed to be finally making some real\n",
      "progress, and we wanted to be a part of it\n",
      "\n",
      "Page 27: 6 CHAPTER 1 What is reinforcement learning?\n",
      "which are composed into elementary shapes, and so on, until you get the complete,\n",
      "complex image. This ability to handle complexity with compositional representations\n",
      "is largely what makes deep learning so powerful.\n",
      "1.2 Reinforcement learning\n",
      "It is importan\n",
      "\n",
      "Page 28: 7Reinforcement learning\n",
      "One added complexity of moving from image processing to the domain of control\n",
      "tasks is the additional element of time. With image processing, we usually train a deep\n",
      "learning algorithm on a fixed data set of images. After a sufficient amount of training,\n",
      "we typically get a hi\n",
      "\n",
      "Page 17: xvi\n",
      "about this book\n",
      "Who should read this book\n",
      "Deep Reinforcement Learning in Action  is a course designed to take you from the very\n",
      "foundational concepts in reinforcement learning all the way to implementing the lat-\n",
      "est algorithms. As a course, each chapter centers around one major project meant to\n",
      "\n",
      "Page 357: 336\n",
      "appendix\n",
      "Mathematics,\n",
      "deep learning, PyTorch\n",
      "This appendix offers a rapid review of deep learning, the relevant mathematics we\n",
      "use in this book, and how to implement deep learning models in PyTorch. We’ll\n",
      "cover these topics by demonstrating how to implement a deep learning model in\n",
      "PyTorch to cl\n",
      "\n",
      "Page 39: 18 CHAPTER 1 What is reinforcement learning?\n",
      "at the top of the screen. In that case, we could define constraints—only look at the\n",
      "states when the ball is returning to the paddle, since our actions are not important\n",
      "while we are waiting for the ball at the top of the screen. Or we could provide our o\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newac\\AppData\\Local\\Temp\\ipykernel_15940\\3393742630.py:10: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is deeplearning?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "\n",
    "# Print generated queries\n",
    "generated_queries_list = generate_queries.invoke({\"question\": question})\n",
    "print(\"Generated Queries:\")\n",
    "for query in generated_queries_list:\n",
    "    print(query)\n",
    "    \n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "\n",
    "print(len(docs))\n",
    "for doc in docs:\n",
    "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is is fed to the model without filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Deep learning is a subfield of machine learning that utilizes deep neural networks to process complex data efficiently.\\n- It is characterized by its ability to learn layered representations of input data, allowing for compositional representations of complexity.\\n- Deep learning models are particularly effective for tasks like image classification and prediction, where traditional automated image processing was limited.\\n- The \"deep\" in deep learning refers to the multiple layers in neural networks, which help in learning intricate patterns and features from data.\\n- Deep learning has been instrumental in the success of deep reinforcement learning (DRL), which combines deep learning with reinforcement learning tasks.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "# template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You are a friendly assistant that helps students.\n",
    "Answer the query using only the sources provided below in a friendly and concise bulleted manner.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {question}\n",
    "Sources:\\n{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | model2\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking the retrieved documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(retrieved_docs: list[list], k: int = 70):\n",
    "    \"\"\" Reciprocal Rank Fusion \"\"\"\n",
    "    # Get unique union of retrieved docs\n",
    "    unique_docs = get_unique_union(retrieved_docs)\n",
    "    \n",
    "    # Initialize a dictionary to store the RRF scores\n",
    "    rrf_scores = {dumps(doc): 0 for doc in unique_docs}\n",
    "    \n",
    "    # Calculate RRF scores\n",
    "    for docs in retrieved_docs:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str in rrf_scores:\n",
    "                rrf_scores[doc_str] += 1 / (k + rank + 1)\n",
    "    \n",
    "    # Sort documents by their RRF scores in descending order\n",
    "    sorted_docs = sorted(unique_docs, key=lambda doc: rrf_scores[dumps(doc)], reverse=True)\n",
    "    \n",
    "    # Return sorted documents and their scores\n",
    "    return sorted_docs, [rrf_scores[dumps(doc)] for doc in sorted_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9d90014e-0d81-4e8b-bfcc-a8f36f65e2b4', metadata={'page': 27, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='6 CHAPTER 1 What is reinforcement learning?\\nwhich are composed into elementary shapes, and so on, until you get the complete,\\ncomplex image. This ability to handle complexity with compositional representations\\nis largely what makes deep learning so powerful.\\n1.2 Reinforcement learning\\nIt is important to distinguish between problems and their solutions, or in other words,\\nbetween the tasks we wish to solve and the algorithms we design to solve them. Deep\\nlearning algorithms can be applied to many problem types and tasks. Image classifica-\\ntion and prediction tasks are common applications of deep learning because auto-\\nmated image processing before deep learning was very limited, given the complexity\\nof images. But there are many other kinds of tasks we might wish to automate, such as\\ndriving a car or balancing a portfolio of stocks and other assets. Driving a car includes\\nsome amount of image processing, but more importantly the algorithm needs to learn\\nhow to act, not merely to classify or predict. These kinds of problems, where decisions\\nmust be made or some behavior must be enacted, are collectively called control tasks.\\nReinforcement learning  is a generic framework for representing and solving control\\ntasks, but within this framework we are free to choose which algorithms we want to\\napply to a particular control task (figure 1.4). Deep learning algorithms are a natural\\nchoice as they are able to process complex data efficiently, and this is why we’ll focus\\non deep reinforcement learning, but much of what you’ll learn in this book is the gen-\\neral reinforcement framework for control tasks (see figure 1.5). Then we’ll look at\\nhow you can design an appropriate deep learning model to fit the framework and\\nsolve a task. This means you will learn a lot about reinforcement learning, and you’ll\\nprobably will learn some things about deep learning that you didn’t know as well.\\nVideo game Game controller\\nUpdates the\\nReinforcement learning\\nalgorithm\\nIs input to Takes action using\\nFigure 1.4 As opposed to an image classifier, a reinforcement \\nlearning algorithm dynamically interacts with data. It continually \\nconsumes data and decides what actions to take—actions that will \\nchange the subsequent data presented to it. A video game screen \\nmight be input data for an RL algorithm, which then decides which \\naction to take using the game controller, and this causes the game \\nto update (e.g. the player moves or fires a weapon).'),\n",
       " Document(id='3030f233-625b-47a5-9da5-c9bd94997bd1', metadata={'page': 24, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='3\\nWhat is reinforcement\\nlearning?\\nComputer languages of the future will be more concerned with goals and less with\\nprocedures specified by the programmer.\\n—Marvin Minksy, 1970 ACM Turing Lecture\\nIf you’re reading this book, you are probably familiar with how deep neural net-\\nworks are used for things like image classification or prediction (and if not, just\\nkeep reading; we also have a crash course in deep learning in the appendix). Deep\\nreinforcement learning  (DRL) is a subfield of machine learning that utilizes deep\\nlearning models (i.e., neural networks) in reinforcement learning (RL) tasks (to be\\ndefined in section 1.2). In image classification we have a bunch of images that cor-\\nrespond to a set of discrete categories, such as images of different kinds of animals,\\nand we want a machine learning model to interpret an image and classify the kind\\nof animal in the image, as in figure 1.1.\\nThis chapter covers\\n\\uf0a1 A brief review of machine learning\\n\\uf0a1 Introducing reinforcement learning as a subfield\\n\\uf0a1 The basic framework of reinforcement learning'),\n",
       " Document(id='8392bfc8-39de-4d53-a1e4-4e251638ea82', metadata={'page': 39, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='18 CHAPTER 1 What is reinforcement learning?\\nat the top of the screen. In that case, we could define constraints—only look at the\\nstates when the ball is returning to the paddle, since our actions are not important\\nwhile we are waiting for the ball at the top of the screen. Or we could provide our own\\nfeatures—instead of providing the raw image, just provide the position of the ball,\\npaddle, and the remaining blocks. However, these methods require the programmer\\nto understand the underlying strategies of the game, and they would not generalize to\\nother environments.\\n That’s where deep learning comes in. A deep learning algorithm can learn to\\nabstract away the details of specific arrangements of pixels and can learn the import-\\nant features of a state. Since a deep learning algorithm has a finite number of param-\\neters, we can use it to compress any possible state into something we can efficiently\\nprocess, and then use that new representation to make our decisions. As a result of\\nusing neural networks, the Atari DQN only had 1792 parameters (convolutional\\nneural network with 16 8 × 8 filters, 32 4 × 4 filters, and a 256-node fully connected\\nhidden layer) as opposed to the 256 28228 key/value pairs that would be needed to\\nstore the entire state space.\\n In the case of the Breakout game, a deep neural network might learn on its own to\\nrecognize the same high-level features a programmer would have to hand-engineer in\\na lookup table approach. That is, it might learn how to “see” the ball, the paddle, the\\nblocks, and to recognize the direction of the ball. That’s pretty amazing given that it’s\\nonly being given raw pixel data. And even more interesting is that the learned high-\\nlevel features may be transferable to other games or environments.\\n Deep learning is the secret sauce that makes all the recent successes in RL possi-\\nble. No other class of algorithms has demonstrated the representational power, effi-\\nciency, and flexibility of deep neural networks. Moreover, neural networks are\\nactually fairly simple!\\n1.7 Our didactic tool: String diagrams\\nThe fundamental concepts of RL have been well-established for decades, but the field\\nis moving very quickly, so any particular new result could soon be out of date. That’s\\nwhy this book focuses on teaching skills, not details with short half-lives. We do cover\\nsome recent advances in the field that will surely be supplanted in the not too distant\\nfuture, but we do so only to build new skills, not because the particular topic we’re\\ncovering is necessarily a time-tested technique. We’re confident that even if some of\\nour examples become dated, the skills you learn will not, and you’ll be prepared to\\ntackle RL problems for a long time to come.\\n Moreover, RL is a huge field with a lot to learn. We can’t possibly hope to cover all\\nof it in this book. Rather than be an exhaustive RL reference or comprehensive\\ncourse, our goal is to teach you the foundations of RL and to sample a few of the most\\nexciting recent developments in the field. We expect that you will be able to take what\\nyou’ve learned here and easily get up to speed in the many other areas of RL. Plus, we'),\n",
       " Document(id='0492f9a7-07b3-4aad-b8a6-53600d19b798', metadata={'page': 14, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='xiii\\npreface\\nDeep reinforcement learning was launched into the spotlight in 2015, when Deep-\\nMind produced an algorithm capable of playing a suite of Atari 2600 games at super-\\nhuman performance. Artificial intelligence seemed to be finally making some real\\nprogress, and we wanted to be a part of it.\\n Both of us have software engineering backgrounds and an interest in neurosci-\\nence, and we’ve been interested in the broader field of artificial intelligence for a long\\ntime (in fact, one of us actually wrote his first neural network before high school in\\nC#). These early experiences did not lead to any sustained interest, since this was\\nbefore the deep learning revolution circa 2012, when the superlative performance of\\ndeep learning was clear. But after seeing the amazing successes of deep learning\\naround this time, we became recommitted to being a part of the exciting and bur-\\ngeoning fields of deep learning and then deep reinforcement learning, and both of\\nus have incorporated machine learning more broadly into our careers in one way or\\nanother. Alex transitioned into a career as a machine learning engineer, making his\\nmark at little-known places like Amazon, and Brandon began using machine learning\\nin academic neuroscience research. As we delved into deep reinforcement learning,\\nwe had to struggle through dozens of textbooks and primary research articles, parsing\\nadvanced mathematics and machine learning theory. Yet we found that the funda-\\nmentals of deep reinforcement learning are actually quite approachable from a soft-\\nware engineering background. All of the math can be easily translated into a language\\nthat any programmer would find quite readable.'),\n",
       " Document(id='f9635fa4-f60d-4860-87eb-cf29ea15b6fa', metadata={'page': 28, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='7Reinforcement learning\\nOne added complexity of moving from image processing to the domain of control\\ntasks is the additional element of time. With image processing, we usually train a deep\\nlearning algorithm on a fixed data set of images. After a sufficient amount of training,\\nwe typically get a high-performance algorithm that we can deploy to some new, unseen\\nimages. We can think of the data set as a “space” of data, where similar images are closer\\ntogether in this abstract space and distinct images are farther apart (figure 1.6). \\n In control tasks, we similarly have a space of data to process, but each piece of data\\nalso has a time dimension—the data exists in both time and space. This means that\\nwhat the algorithm decides at one time is influenced by what happened at a previous\\ntime. This isn’t the case for ordinary image classification and similar problems. Time\\nMachine\\nlearning\\nDeep\\nlearning Can be used as the\\nlearning algorithm for\\nIs a\\nsubset of\\nControl tasks\\nReinforcement\\nlearning\\nIs a framework\\nfor solving Figure 1.5 Deep learning is a \\nsubfield of machine learning. Deep \\nlearning algorithms can be used \\nto power RL approaches to solving \\ncontrol tasks.\\n10 A\\nB\\nC\\nD\\n5\\n0\\n–5\\n–10\\n–10 –5\\nAdj Vb (PP) Vb (Pres) F Char Vb M Nn Vb (Past)\\n0 5 10\\nFigure 1.6 This graphical depiction of words in a 2D space shows each word as a colored point. \\nSimilar words cluster together, and dissimilar words are farther apart. Data naturally lives in some \\nkind of “space” with similar data living closer together. The labels A, B, C, and D point to particular \\nclusters of words that share some semantics.'),\n",
       " Document(id='ed959438-afbe-42e2-9530-b0b0626e7ce6', metadata={'page': 17, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='xvi\\nabout this book\\nWho should read this book\\nDeep Reinforcement Learning in Action  is a course designed to take you from the very\\nfoundational concepts in reinforcement learning all the way to implementing the lat-\\nest algorithms. As a course, each chapter centers around one major project meant to\\nillustrate the topic or concept of that chapter. We’ve designed each project to be\\nsomething that can be efficiently run on a modern laptop; we don’t expect you to\\nhave access to expensive GPUs or cloud computing resources (though access to these\\nresources does make things run faster). \\n This book is for individuals with a programming background, in particular, a work-\\ning knowledge of Python, and for people who have at least a basic understanding of\\nneural networks (a.k.a. deep learning). By “basic understanding,” we mean that you\\nhave at least tried implementing a simple neural network in Python even if you didn’t\\nfully understand what was going on under the hood. Although this book is focused on\\nusing neural networks for the purposes of reinforcement learning, you will also proba-\\nbly learn a lot of new things about deep learning in general that can be applied to\\nother problems outside of reinforcement learning, so you do not need to be an expert\\nat deep learning before jumping into deep reinforcement learning. '),\n",
       " Document(id='751dfe74-6c27-44e6-8182-5e9300db5269', metadata={'page': 357, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='336\\nappendix\\nMathematics,\\ndeep learning, PyTorch\\nThis appendix offers a rapid review of deep learning, the relevant mathematics we\\nuse in this book, and how to implement deep learning models in PyTorch. We’ll\\ncover these topics by demonstrating how to implement a deep learning model in\\nPyTorch to classify images of handwritten digits from the famous MNIST dataset.\\nDeep learning algorithms , which are also called artificial neural networks , are rela -\\ntively simple mathematical functions and mostly just require an understanding of\\nvectors and matrices. Training a neural network, however, requires an understand -\\ning of the basics of calculus, namely the derivative. The fundamentals of applied\\ndeep learning therefore require only knowing how to multiply vectors and matrices\\nand take the derivative of multivariable functions, which we’ll review here. Theoreti-\\ncal machine learning  refers to the field that rigorously studies the properties and\\nbehavior of machine learning algorithms and yields new approaches and algo -\\nrithms. Theoretical machine learning involves advanced graduate-level mathemat -\\nics that covers a wide variety of mathematical disciplines that are outside the scope\\nof this book. In this book we only utilize informal mathematics in order to achieve\\nour practical aims, not rigorous proof-based mathematics.\\nA.1 Linear algebra\\nLinear algebra is the study of linear transformations. A linear transformation is a trans-\\nformation (e.g., a function) in which the sum of the transformation of two inputs\\nseparately, such as T(a) and T(b), is the same as summing the two inputs and trans-\\nforming them together, i.e., T(a + b) = T(a) + T(b). A linear transformation also has\\nthe property that T(a ⋅ b) = a ⋅ T(b). Linear transformations are said to preserve'),\n",
       " Document(id='8e2c0019-2135-45b9-afcc-972b5561715d', metadata={'page': 306, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='285Machine learning interpretability with attention and relational biases\\nrepresentation of the features within the image. In a sense, we hope the SAM will con-\\nvert a raw image into a graph structure, and that the graph structure it constructs will\\nbe somewhat interpretable. If we train a SAM on a bunch of images of people playing\\nbasketball, for example, we might hope it learns to associate the people with the ball,\\nand the ball with the basket. That is, we want it to learn that the ball is a node, the bas-\\nket is a node, and the players are nodes and to learn the appropriate edges between\\nthe nodes. Such a representation would give us much more insight into the mechan -\\nics of our machine learning model than would a conventional convolutional neural\\nnetwork or the like.\\n Different neural network architectures such as convolutional, recurrent, or atten -\\ntion have different inductive biases  that can improve learning when those biases are\\naccurate. Inductive reasoning is when you observe some data and infer a more general\\npattern or rule from it. Deductive reasoning is what we do in mathematics when we start\\nwith some premises and by following logical rules assumed to be true, we can make a\\nconclusion with certainty. \\n For example, the syllogism “All planets are round. Earth is a planet. Therefore, the\\nEarth is round” is a form of deductive reasoning. There is no uncertainty about the\\nconclusion if we assume the premises to be true. \\n Inductive reasoning, on the other hand, can only lead to probabilistic conclusions.\\nInductive reasoning is what you do when you play a game like chess. You cannot\\ndeduce what the other player is going to do; you have to rely on the available evidence\\nInput\\nGraph neural network\\nOutput\\nFigure 10.2 A graph neural network can directly operate on a graph, compute \\nover the nodes and edges, and return an updated graph. In this example, the graph \\nneural network decides to remove the edge connecting the bottom two nodes. This \\nis an abstract example, but the nodes could represent real world variables and the \\narrows represent causal direction, so the algorithm would be learning to infer \\ncausal pathways between variables.'),\n",
       " Document(id='a23cdbc6-7abc-4870-9d2d-833920175ec2', metadata={'page': 42, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='21Summary\\ngenerative adversarial networks, evolutionary methods, meta-learning, and transfer\\nlearning. Again, this is all in line with our skills-focused mode of teaching, so the par-\\nticulars of these advances is not what’s important.\\nSummary\\n\\uf0a1 Reinforcement learning is a subclass of machine learning. RL algorithms learn\\nby maximizing rewards in some environment, and they’re useful when a prob-\\nlem involves making decisions or taking actions. RL algorithms can, in princi-\\nple, employ any statistical learning model, but it has become increasingly popular\\nand effective to use deep neural networks.\\nFigure 1.15 A depiction of a Go board, an ancient Chinese game that Google DeepMind \\nused as a testbed for its AlphaGo reinforcement learning algorithm. Professional Go \\nplayer Lee Sedol only won one game out of five, marking a turning point for reinforcement \\nlearning, as Go was long thought to be impervious to the kind of algorithmic reasoning \\nthat chess is subject to. Source: http:/ /mng.bz/DNX0. '),\n",
       " Document(id='64c563b5-ed94-46af-823c-6890fc2073be', metadata={'page': 25, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='4 CHAPTER 1 What is reinforcement learning?\\n1.1 The “deep” in deep reinforcement learning\\nDeep learning models are just one of many kinds of machine learning models we\\ncan use to classify images. In general, we just need some sort of function that takes\\nin an image and returns a class label (in this case, the label identifying which kind of\\nanimal is depicted in the image), and usually this function has a fixed set of adjust-\\nable parameters —we call these kinds of models parametric models. We start with a\\nparametric model whose parameters are initialized to random values—this will pro-\\nduce random class labels for the input images. Then we use a training procedure to\\nadjust the parameters so the function iteratively gets better and better at correctly\\nclassifying the images. At some point, the parameters will be at an optimal set of val-\\nues, meaning that the model cannot get any better at the classification task. Para-\\nmetric models can also be used for regression, where we try to fit a model to a set of\\ndata so we can make predictions for unseen data (figure 1.2). A more sophisticated\\napproach might perform even better if it had more parameters or a better internal\\narchitecture.\\n Deep neural networks are popular because they are in many cases the most accu-\\nrate parametric machine learning models for a given task, like image classification.\\nThis is largely due to the way they represent data. Deep neural networks have many\\nlayers (hence the “deep”), which induces the model to learn layered representations\\nof input data. This layered representation is a form of compositionality, meaning that a\\ncomplex piece of data is represented as the combination of more elementary compo-\\nnents, and those components can be further broken down into even simpler compo-\\nnents, and so on, until you get to atomic units.\\n Human language is compositional (figure 1.3). For example, a book is composed\\nof chapters, chapters are composed of paragraphs, paragraphs are composed of sen-\\ntences, and so on, until you get to individual words, which are the smallest units of\\nmeaning. Yet each individual level conveys meaning—an entire book is meant to con-\\nvey meaning, and its individual paragraphs are meant to convey smaller points. Deep\\nneural networks can likewise learn a compositional representation of data—for exam-\\nple, they can represent an image as the composition of primitive contours and textures,\\nImage classiﬁer\\nCat\\nDog\\nClass labels\\nImage classiﬁer\\nCat\\nDog\\nFigure 1.1 An image classifier is \\na function or learning algorithm \\nthat takes in an image and returns \\na class label, classifying the image \\ninto one of a finite number of \\npossible categories or classes.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reciprocal_rank_fusion([docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='751dfe74-6c27-44e6-8182-5e9300db5269', metadata={'page': 357, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='336\\nappendix\\nMathematics,\\ndeep learning, PyTorch\\nThis appendix offers a rapid review of deep learning, the relevant mathematics we\\nuse in this book, and how to implement deep learning models in PyTorch. We’ll\\ncover these topics by demonstrating how to implement a deep learning model in\\nPyTorch to classify images of handwritten digits from the famous MNIST dataset.\\nDeep learning algorithms , which are also called artificial neural networks , are rela -\\ntively simple mathematical functions and mostly just require an understanding of\\nvectors and matrices. Training a neural network, however, requires an understand -\\ning of the basics of calculus, namely the derivative. The fundamentals of applied\\ndeep learning therefore require only knowing how to multiply vectors and matrices\\nand take the derivative of multivariable functions, which we’ll review here. Theoreti-\\ncal machine learning  refers to the field that rigorously studies the properties and\\nbehavior of machine learning algorithms and yields new approaches and algo -\\nrithms. Theoretical machine learning involves advanced graduate-level mathemat -\\nics that covers a wide variety of mathematical disciplines that are outside the scope\\nof this book. In this book we only utilize informal mathematics in order to achieve\\nour practical aims, not rigorous proof-based mathematics.\\nA.1 Linear algebra\\nLinear algebra is the study of linear transformations. A linear transformation is a trans-\\nformation (e.g., a function) in which the sum of the transformation of two inputs\\nseparately, such as T(a) and T(b), is the same as summing the two inputs and trans-\\nforming them together, i.e., T(a + b) = T(a) + T(b). A linear transformation also has\\nthe property that T(a ⋅ b) = a ⋅ T(b). Linear transformations are said to preserve'),\n",
       " Document(id='0492f9a7-07b3-4aad-b8a6-53600d19b798', metadata={'page': 14, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='xiii\\npreface\\nDeep reinforcement learning was launched into the spotlight in 2015, when Deep-\\nMind produced an algorithm capable of playing a suite of Atari 2600 games at super-\\nhuman performance. Artificial intelligence seemed to be finally making some real\\nprogress, and we wanted to be a part of it.\\n Both of us have software engineering backgrounds and an interest in neurosci-\\nence, and we’ve been interested in the broader field of artificial intelligence for a long\\ntime (in fact, one of us actually wrote his first neural network before high school in\\nC#). These early experiences did not lead to any sustained interest, since this was\\nbefore the deep learning revolution circa 2012, when the superlative performance of\\ndeep learning was clear. But after seeing the amazing successes of deep learning\\naround this time, we became recommitted to being a part of the exciting and bur-\\ngeoning fields of deep learning and then deep reinforcement learning, and both of\\nus have incorporated machine learning more broadly into our careers in one way or\\nanother. Alex transitioned into a career as a machine learning engineer, making his\\nmark at little-known places like Amazon, and Brandon began using machine learning\\nin academic neuroscience research. As we delved into deep reinforcement learning,\\nwe had to struggle through dozens of textbooks and primary research articles, parsing\\nadvanced mathematics and machine learning theory. Yet we found that the funda-\\nmentals of deep reinforcement learning are actually quite approachable from a soft-\\nware engineering background. All of the math can be easily translated into a language\\nthat any programmer would find quite readable.'),\n",
       " Document(id='3030f233-625b-47a5-9da5-c9bd94997bd1', metadata={'page': 24, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='3\\nWhat is reinforcement\\nlearning?\\nComputer languages of the future will be more concerned with goals and less with\\nprocedures specified by the programmer.\\n—Marvin Minksy, 1970 ACM Turing Lecture\\nIf you’re reading this book, you are probably familiar with how deep neural net-\\nworks are used for things like image classification or prediction (and if not, just\\nkeep reading; we also have a crash course in deep learning in the appendix). Deep\\nreinforcement learning  (DRL) is a subfield of machine learning that utilizes deep\\nlearning models (i.e., neural networks) in reinforcement learning (RL) tasks (to be\\ndefined in section 1.2). In image classification we have a bunch of images that cor-\\nrespond to a set of discrete categories, such as images of different kinds of animals,\\nand we want a machine learning model to interpret an image and classify the kind\\nof animal in the image, as in figure 1.1.\\nThis chapter covers\\n\\uf0a1 A brief review of machine learning\\n\\uf0a1 Introducing reinforcement learning as a subfield\\n\\uf0a1 The basic framework of reinforcement learning'),\n",
       " Document(id='9d90014e-0d81-4e8b-bfcc-a8f36f65e2b4', metadata={'page': 27, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='6 CHAPTER 1 What is reinforcement learning?\\nwhich are composed into elementary shapes, and so on, until you get the complete,\\ncomplex image. This ability to handle complexity with compositional representations\\nis largely what makes deep learning so powerful.\\n1.2 Reinforcement learning\\nIt is important to distinguish between problems and their solutions, or in other words,\\nbetween the tasks we wish to solve and the algorithms we design to solve them. Deep\\nlearning algorithms can be applied to many problem types and tasks. Image classifica-\\ntion and prediction tasks are common applications of deep learning because auto-\\nmated image processing before deep learning was very limited, given the complexity\\nof images. But there are many other kinds of tasks we might wish to automate, such as\\ndriving a car or balancing a portfolio of stocks and other assets. Driving a car includes\\nsome amount of image processing, but more importantly the algorithm needs to learn\\nhow to act, not merely to classify or predict. These kinds of problems, where decisions\\nmust be made or some behavior must be enacted, are collectively called control tasks.\\nReinforcement learning  is a generic framework for representing and solving control\\ntasks, but within this framework we are free to choose which algorithms we want to\\napply to a particular control task (figure 1.4). Deep learning algorithms are a natural\\nchoice as they are able to process complex data efficiently, and this is why we’ll focus\\non deep reinforcement learning, but much of what you’ll learn in this book is the gen-\\neral reinforcement framework for control tasks (see figure 1.5). Then we’ll look at\\nhow you can design an appropriate deep learning model to fit the framework and\\nsolve a task. This means you will learn a lot about reinforcement learning, and you’ll\\nprobably will learn some things about deep learning that you didn’t know as well.\\nVideo game Game controller\\nUpdates the\\nReinforcement learning\\nalgorithm\\nIs input to Takes action using\\nFigure 1.4 As opposed to an image classifier, a reinforcement \\nlearning algorithm dynamically interacts with data. It continually \\nconsumes data and decides what actions to take—actions that will \\nchange the subsequent data presented to it. A video game screen \\nmight be input data for an RL algorithm, which then decides which \\naction to take using the game controller, and this causes the game \\nto update (e.g. the player moves or fires a weapon).'),\n",
       " Document(id='64c563b5-ed94-46af-823c-6890fc2073be', metadata={'page': 25, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='4 CHAPTER 1 What is reinforcement learning?\\n1.1 The “deep” in deep reinforcement learning\\nDeep learning models are just one of many kinds of machine learning models we\\ncan use to classify images. In general, we just need some sort of function that takes\\nin an image and returns a class label (in this case, the label identifying which kind of\\nanimal is depicted in the image), and usually this function has a fixed set of adjust-\\nable parameters —we call these kinds of models parametric models. We start with a\\nparametric model whose parameters are initialized to random values—this will pro-\\nduce random class labels for the input images. Then we use a training procedure to\\nadjust the parameters so the function iteratively gets better and better at correctly\\nclassifying the images. At some point, the parameters will be at an optimal set of val-\\nues, meaning that the model cannot get any better at the classification task. Para-\\nmetric models can also be used for regression, where we try to fit a model to a set of\\ndata so we can make predictions for unseen data (figure 1.2). A more sophisticated\\napproach might perform even better if it had more parameters or a better internal\\narchitecture.\\n Deep neural networks are popular because they are in many cases the most accu-\\nrate parametric machine learning models for a given task, like image classification.\\nThis is largely due to the way they represent data. Deep neural networks have many\\nlayers (hence the “deep”), which induces the model to learn layered representations\\nof input data. This layered representation is a form of compositionality, meaning that a\\ncomplex piece of data is represented as the combination of more elementary compo-\\nnents, and those components can be further broken down into even simpler compo-\\nnents, and so on, until you get to atomic units.\\n Human language is compositional (figure 1.3). For example, a book is composed\\nof chapters, chapters are composed of paragraphs, paragraphs are composed of sen-\\ntences, and so on, until you get to individual words, which are the smallest units of\\nmeaning. Yet each individual level conveys meaning—an entire book is meant to con-\\nvey meaning, and its individual paragraphs are meant to convey smaller points. Deep\\nneural networks can likewise learn a compositional representation of data—for exam-\\nple, they can represent an image as the composition of primitive contours and textures,\\nImage classiﬁer\\nCat\\nDog\\nClass labels\\nImage classiﬁer\\nCat\\nDog\\nFigure 1.1 An image classifier is \\na function or learning algorithm \\nthat takes in an image and returns \\na class label, classifying the image \\ninto one of a finite number of \\npossible categories or classes.'),\n",
       " Document(id='8392bfc8-39de-4d53-a1e4-4e251638ea82', metadata={'page': 39, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='18 CHAPTER 1 What is reinforcement learning?\\nat the top of the screen. In that case, we could define constraints—only look at the\\nstates when the ball is returning to the paddle, since our actions are not important\\nwhile we are waiting for the ball at the top of the screen. Or we could provide our own\\nfeatures—instead of providing the raw image, just provide the position of the ball,\\npaddle, and the remaining blocks. However, these methods require the programmer\\nto understand the underlying strategies of the game, and they would not generalize to\\nother environments.\\n That’s where deep learning comes in. A deep learning algorithm can learn to\\nabstract away the details of specific arrangements of pixels and can learn the import-\\nant features of a state. Since a deep learning algorithm has a finite number of param-\\neters, we can use it to compress any possible state into something we can efficiently\\nprocess, and then use that new representation to make our decisions. As a result of\\nusing neural networks, the Atari DQN only had 1792 parameters (convolutional\\nneural network with 16 8 × 8 filters, 32 4 × 4 filters, and a 256-node fully connected\\nhidden layer) as opposed to the 256 28228 key/value pairs that would be needed to\\nstore the entire state space.\\n In the case of the Breakout game, a deep neural network might learn on its own to\\nrecognize the same high-level features a programmer would have to hand-engineer in\\na lookup table approach. That is, it might learn how to “see” the ball, the paddle, the\\nblocks, and to recognize the direction of the ball. That’s pretty amazing given that it’s\\nonly being given raw pixel data. And even more interesting is that the learned high-\\nlevel features may be transferable to other games or environments.\\n Deep learning is the secret sauce that makes all the recent successes in RL possi-\\nble. No other class of algorithms has demonstrated the representational power, effi-\\nciency, and flexibility of deep neural networks. Moreover, neural networks are\\nactually fairly simple!\\n1.7 Our didactic tool: String diagrams\\nThe fundamental concepts of RL have been well-established for decades, but the field\\nis moving very quickly, so any particular new result could soon be out of date. That’s\\nwhy this book focuses on teaching skills, not details with short half-lives. We do cover\\nsome recent advances in the field that will surely be supplanted in the not too distant\\nfuture, but we do so only to build new skills, not because the particular topic we’re\\ncovering is necessarily a time-tested technique. We’re confident that even if some of\\nour examples become dated, the skills you learn will not, and you’ll be prepared to\\ntackle RL problems for a long time to come.\\n Moreover, RL is a huge field with a lot to learn. We can’t possibly hope to cover all\\nof it in this book. Rather than be an exhaustive RL reference or comprehensive\\ncourse, our goal is to teach you the foundations of RL and to sample a few of the most\\nexciting recent developments in the field. We expect that you will be able to take what\\nyou’ve learned here and easily get up to speed in the many other areas of RL. Plus, we'),\n",
       " Document(id='a23cdbc6-7abc-4870-9d2d-833920175ec2', metadata={'page': 42, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='21Summary\\ngenerative adversarial networks, evolutionary methods, meta-learning, and transfer\\nlearning. Again, this is all in line with our skills-focused mode of teaching, so the par-\\nticulars of these advances is not what’s important.\\nSummary\\n\\uf0a1 Reinforcement learning is a subclass of machine learning. RL algorithms learn\\nby maximizing rewards in some environment, and they’re useful when a prob-\\nlem involves making decisions or taking actions. RL algorithms can, in princi-\\nple, employ any statistical learning model, but it has become increasingly popular\\nand effective to use deep neural networks.\\nFigure 1.15 A depiction of a Go board, an ancient Chinese game that Google DeepMind \\nused as a testbed for its AlphaGo reinforcement learning algorithm. Professional Go \\nplayer Lee Sedol only won one game out of five, marking a turning point for reinforcement \\nlearning, as Go was long thought to be impervious to the kind of algorithmic reasoning \\nthat chess is subject to. Source: http:/ /mng.bz/DNX0. '),\n",
       " Document(id='f9635fa4-f60d-4860-87eb-cf29ea15b6fa', metadata={'page': 28, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='7Reinforcement learning\\nOne added complexity of moving from image processing to the domain of control\\ntasks is the additional element of time. With image processing, we usually train a deep\\nlearning algorithm on a fixed data set of images. After a sufficient amount of training,\\nwe typically get a high-performance algorithm that we can deploy to some new, unseen\\nimages. We can think of the data set as a “space” of data, where similar images are closer\\ntogether in this abstract space and distinct images are farther apart (figure 1.6). \\n In control tasks, we similarly have a space of data to process, but each piece of data\\nalso has a time dimension—the data exists in both time and space. This means that\\nwhat the algorithm decides at one time is influenced by what happened at a previous\\ntime. This isn’t the case for ordinary image classification and similar problems. Time\\nMachine\\nlearning\\nDeep\\nlearning Can be used as the\\nlearning algorithm for\\nIs a\\nsubset of\\nControl tasks\\nReinforcement\\nlearning\\nIs a framework\\nfor solving Figure 1.5 Deep learning is a \\nsubfield of machine learning. Deep \\nlearning algorithms can be used \\nto power RL approaches to solving \\ncontrol tasks.\\n10 A\\nB\\nC\\nD\\n5\\n0\\n–5\\n–10\\n–10 –5\\nAdj Vb (PP) Vb (Pres) F Char Vb M Nn Vb (Past)\\n0 5 10\\nFigure 1.6 This graphical depiction of words in a 2D space shows each word as a colored point. \\nSimilar words cluster together, and dissimilar words are farther apart. Data naturally lives in some \\nkind of “space” with similar data living closer together. The labels A, B, C, and D point to particular \\nclusters of words that share some semantics.'),\n",
       " Document(id='ed959438-afbe-42e2-9530-b0b0626e7ce6', metadata={'page': 17, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='xvi\\nabout this book\\nWho should read this book\\nDeep Reinforcement Learning in Action  is a course designed to take you from the very\\nfoundational concepts in reinforcement learning all the way to implementing the lat-\\nest algorithms. As a course, each chapter centers around one major project meant to\\nillustrate the topic or concept of that chapter. We’ve designed each project to be\\nsomething that can be efficiently run on a modern laptop; we don’t expect you to\\nhave access to expensive GPUs or cloud computing resources (though access to these\\nresources does make things run faster). \\n This book is for individuals with a programming background, in particular, a work-\\ning knowledge of Python, and for people who have at least a basic understanding of\\nneural networks (a.k.a. deep learning). By “basic understanding,” we mean that you\\nhave at least tried implementing a simple neural network in Python even if you didn’t\\nfully understand what was going on under the hood. Although this book is focused on\\nusing neural networks for the purposes of reinforcement learning, you will also proba-\\nbly learn a lot of new things about deep learning in general that can be applied to\\nother problems outside of reinforcement learning, so you do not need to be an expert\\nat deep learning before jumping into deep reinforcement learning. '),\n",
       " Document(id='8e2c0019-2135-45b9-afcc-972b5561715d', metadata={'page': 306, 'source': 'papers\\\\Alexander Zai, Brandon Brown - Deep Reinforcement Learning in Action-Manning Publications (2020).pdf'}, page_content='285Machine learning interpretability with attention and relational biases\\nrepresentation of the features within the image. In a sense, we hope the SAM will con-\\nvert a raw image into a graph structure, and that the graph structure it constructs will\\nbe somewhat interpretable. If we train a SAM on a bunch of images of people playing\\nbasketball, for example, we might hope it learns to associate the people with the ball,\\nand the ball with the basket. That is, we want it to learn that the ball is a node, the bas-\\nket is a node, and the players are nodes and to learn the appropriate edges between\\nthe nodes. Such a representation would give us much more insight into the mechan -\\nics of our machine learning model than would a conventional convolutional neural\\nnetwork or the like.\\n Different neural network architectures such as convolutional, recurrent, or atten -\\ntion have different inductive biases  that can improve learning when those biases are\\naccurate. Inductive reasoning is when you observe some data and infer a more general\\npattern or rule from it. Deductive reasoning is what we do in mathematics when we start\\nwith some premises and by following logical rules assumed to be true, we can make a\\nconclusion with certainty. \\n For example, the syllogism “All planets are round. Earth is a planet. Therefore, the\\nEarth is round” is a form of deductive reasoning. There is no uncertainty about the\\nconclusion if we assume the premises to be true. \\n Inductive reasoning, on the other hand, can only lead to probabilistic conclusions.\\nInductive reasoning is what you do when you play a game like chess. You cannot\\ndeduce what the other player is going to do; you have to rely on the available evidence\\nInput\\nGraph neural network\\nOutput\\nFigure 10.2 A graph neural network can directly operate on a graph, compute \\nover the nodes and edges, and return an updated graph. In this example, the graph \\nneural network decides to remove the edge connecting the bottom two nodes. This \\nis an abstract example, but the nodes could represent real world variables and the \\narrows represent causal direction, so the algorithm would be learning to infer \\ncausal pathways between variables.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Deep learning algorithms, also known as artificial neural networks, are relatively simple mathematical functions that primarily require an understanding of vectors and matrices.\\n- Training a neural network necessitates knowledge of calculus, particularly derivatives.\\n- Deep learning models are a subset of machine learning models that can classify images and handle complex data efficiently.\\n- They utilize layered representations of data, allowing them to learn compositional structures, which is a key aspect of their power.\\n- Deep learning is particularly effective for tasks like image classification and prediction, as it can abstract important features from raw data.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are a friendly assistant that helps students.\n",
    "Answer the query using only the sources provided below in a friendly and concise bulleted manner.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {question}\n",
    "Sources:\\n{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | model2\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLaying with llm judge\n",
    "\n",
    "##### self rag\n",
    "##### llm jude\n",
    "\n",
    "2 types of retriver: re-ranker and llm-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

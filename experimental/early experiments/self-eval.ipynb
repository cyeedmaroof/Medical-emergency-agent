{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_azure_openai_model, get_azure_openai_chat_model, create_vector_store\n",
    "\n",
    "model = get_azure_openai_chat_model()\n",
    "vector_store = create_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load .txt files\n",
    "\n",
    "txt_folder_path = r\"C:\\Users\\newac\\OneDrive\\Desktop\\ocr_test_data\\ocr_text\"\n",
    "txt_files = [f for f in os.listdir(txt_folder_path) if f.endswith('.txt')]\n",
    "\n",
    "txt_docs = []\n",
    "for txt_file in txt_files:\n",
    "    loader = TextLoader(os.path.join(txt_folder_path, txt_file))\n",
    "    txt_docs.extend(loader.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=100\n",
    ")\n",
    "# Split the text documents into chunks\n",
    "txt_doc_splits = text_splitter.split_documents(txt_docs)\n",
    "\n",
    "# Add the text chunks to the vector store\n",
    "_ = vector_store.add_documents(documents=txt_doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDFs\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "folder_path = \"papers\"\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "pages = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(os.path.join(folder_path, pdf_file))\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add docs to vector store\n",
    "# Index chunks\n",
    "# _ = vector_store.add_documents(documents=doc_splits)\n",
    "\n",
    "# Add pdf pages to vector store\n",
    "_ = vector_store.add_documents(documents=pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrival\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to break the task into sections and define nodes for each step:\n",
    "\n",
    "- Retrieve Node – Fetch relevant documents.\n",
    "- Grade Node – Evaluate document relevance.\n",
    "- Decision: Docs Relevant? – If yes, move to generation; if no, re-write the question.\n",
    "- Generate Node – Generate a response.\n",
    "- Decision: Hallucinations? – If hallucinations are detected, loop back to generation.\n",
    "- Decision: Answers Question? – If the response is valid, return the answer; otherwise, loop back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1354: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\newac\\AppData\\Local\\Temp\\ipykernel_18080\\620460170.py:34: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "#### Grader retrieval\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = model\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.  \\n\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader #| StrOutputParser()\n",
    "question = \"Why does Harry accuse Remus Lupin of being a coward?\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": docs}))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    answer_grade: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### nodes\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents for the given question.\n",
    "    \"\"\"\n",
    "    print(\"---Retrieving documents---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    return {\"question\": question, \"documents\": docs}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate a very concise answer to the question.\n",
    "    \"\"\"\n",
    "    print(\"---Generating answer---\")\n",
    "    question = state[\"question\"]\n",
    "    documents_from_state = state[\"documents\"]\n",
    "\n",
    "    # Format documents for context.\n",
    "    # Assumes documents_from_state is a list of dictionaries,\n",
    "    # where each dictionary has a \"document\" key holding a Document object.\n",
    "    context_str = \"\\n\\n\".join(\n",
    "        [item[\"document\"].page_content for item in documents_from_state if \"document\" in item and hasattr(item[\"document\"], \"page_content\")]\n",
    "    )\n",
    "\n",
    "    # Prompt for very concise answers\n",
    "    # The original \"rlm/rag-prompt\" asks for \"Use three sentences maximum and keep the answer concise.\"\n",
    "    # This custom prompt emphasizes \"VERY concise, ideally one or two sentences.\"\n",
    "    concise_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Keep your answer VERY concise. \"),\n",
    "        (\"human\", \"Question: {question}\\nContext: {context}\\nAnswer:\")\n",
    "    ])\n",
    "\n",
    "    # Ensure 'model' is defined in the global scope or passed to this function\n",
    "    # model = get_azure_openai_chat_model() # Or however it's made available\n",
    "\n",
    "    rag_chain = concise_prompt | model | StrOutputParser()\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": context_str, \"question\": question})\n",
    "    return {\"documents\": documents_from_state, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Grade the relevance of retrieved documents.\n",
    "    \"\"\"\n",
    "    print(\"---Grading documents---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    graded_docs = []\n",
    "    for doc in documents:\n",
    "        # print(\"i am hereee\")\n",
    "        result = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content})\n",
    "        print(result)\n",
    "        grade = result.binary_score\n",
    "        if grade == \"yes\":\n",
    "            graded_docs.append({\"document\": doc, \"grade\": result})\n",
    "\n",
    "    return {\"question\": question, \"documents\": graded_docs}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edge\n",
    "def decide_generation(state):\n",
    "    \"\"\"\n",
    "    Decide whether to generate an answer based on the graded documents.\n",
    "    \"\"\"\n",
    "    print(\"---Deciding whether to generate an answer---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    if len(documents) > 0:\n",
    "        return \"generate\"\n",
    "    else:\n",
    "         print(\"no relevant document found, maybe rephrase the question\")\n",
    "         return \"end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "graphA = StateGraph(GraphState)\n",
    "# graph.add_node(START, \"retrieve\")\n",
    "graphA.add_node(\"retrieve\", retrieve)\n",
    "graphA.add_node(\"generate\", generate)\n",
    "graphA.add_node(\"grade_documents\", grade_documents)\n",
    "\n",
    "# # Add edges (transitions)\n",
    "graphA.add_edge(START, \"retrieve\")\n",
    "# graph.add_edge(\"retrieve\", \"generate\")\n",
    "graphA.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graphA.add_conditional_edges(\"grade_documents\", decide_generation,{\n",
    "    \"generate\": \"generate\",\n",
    "    \"end\": END\n",
    "})\n",
    "graphA.add_edge(\"generate\", END)\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "graph_runnable = graphA.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_runnable.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"advice for an child having heart attack no cpr needed\"}\n",
    "for output in graph_runnable.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Why does Harry accuse Remus Lupin of being a coward?\",\n",
    "    \"Who is R.A.B.?\",\n",
    "    \"According to legend, what would a person become if he could assemble the Deathly Hallows?\",\n",
    "    \"What is Ariana Dumbledore rumored to be?\",\n",
    "    \"What is written on Harrys parents gravestone?\",\n",
    "    \"Why does Krum want to fight Xenophilius Lovegood?\",\n",
    "    \"Why does Voldemort seek the Elder Wand?\",\n",
    "    \"Whose eye does Harry see in his magic mirror shard?\",\n",
    "    \"What is inside the Snitch that Dumbledore leaves Harry?\",\n",
    "    \"Who does Voldemort initially borrow a wand from in hopes of defeating Harry?\",\n",
    "    # \"Where do Harry, Ron, and Hermione first stay during their journey to find the Horcuxes?\",\n",
    "    # \"Who becomes the new Headmaster at Hogwarts?\",\n",
    "    # \"Which character does Harry take the appearance of during his visit to the Ministry of Magic?\",\n",
    "    # \"What type of Patronus appears to lead Harry to the Sword of Godric Gryffindor?\",\n",
    "    # \"Who accidentally breaks Harry's wand?\",\n",
    "    # \"Where do Harry, Ron, and Hermione venture to find Hufflepuff's Cup?\",\n",
    "    # \"Who tells Harry, Hermione, and Ron the tale of the Deathly Hallows?\",\n",
    "    # \"Where is the gravesite of James and Lily Potter located?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Harry accuses Remus Lupin of being a coward because he believes Lupin is abandoning his child for the sake of adventure, contrasting it with his father's sacrifice.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: A person who assembles the Deathly Hallows would become the master of Death.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Ariana Dumbledore is rumored to be a Squib.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: The gravestone reads: \"James Potter Lily Potter Born 27 March 1960 Born 30 January 1960 Died 31 October 1981 Died 31 October 1981 The last enemy that shall be destroyed is death.\"\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Krum wants to fight Xenophilius Lovegood because he believes Lovegood is wearing Grindelwald's symbol, which Krum associates with the dark wizard who killed many people, including his grandfather.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Voldemort seeks the Elder Wand to master it, believing that doing so will allow him to finally defeat Harry Potter, as he is not its true master due to Snape having killed Dumbledore, the wand's previous owner.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Harry sees Aberforth's eye in the magic mirror shard.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: The Snitch contains the ring, which is one of the Deathly Hallows.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "---Generating answer---\n",
      "Generated Answer: Voldemort initially borrows a wand from Lucius Malfoy.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the graph\n",
    "for question in questions:\n",
    "    initial_state = {\"question\": question}\n",
    "    final_state = graph_runnable.invoke(initial_state)\n",
    "    if final_state[\"generation\"] is None:\n",
    "        print(f\"No answer generated for question: {question}\")\n",
    "        continue\n",
    "    else:\n",
    "        # Print results\n",
    "        print(\"Question:\", final_state[\"question\"])\n",
    "        print(\"Generated Answer:\", final_state[\"generation\"])\n",
    "    # print(\"Retrieved Documents:\", final_state[\"documents\"])\n",
    "    # print(\"Original Question:\", final_state[\"question\"])\n",
    "    # print(\"Document Scores:\", final_state[\"scores\"])\n",
    "    print(\"\\n---\\n\")\n",
    "# initial_state = {\"question\": \"What are the main components of deep q-network in RL? give only breif explanation\"}\n",
    "# final_state = graph_runnable.invoke(initial_state)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Generated Answer:\", final_state[\"generation\"])\n",
    "# print(\"Retrieved Documents:\", final_state[\"documents\"])\n",
    "# print(\"Original Question:\", final_state[\"question\"])\n",
    "# # print(\"Document Scores:\", final_state[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### adding question paraphrasing and understanding\n",
    "\n",
    "#node\n",
    "def question_understanding_and_rephrasing(state):\n",
    "    \"\"\"\n",
    "    Understand and rephrase the question.\n",
    "    \"\"\"\n",
    "    print(\"---Understanding and rephrasing question---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # # Prompt\n",
    "    # system = \"\"\"You are an AI assistant specializing in question analysis.\n",
    "    #     Your task is to:\n",
    "    #     1. Analyze the user's question for ambiguity, implicit context, or missing details\n",
    "    #     2. Identify key concepts and terms that should be included in the search\n",
    "    #     3. Create a more detailed search query that would retrieve better documents\n",
    "    #     4. Consider multiple interpretations if the question is ambiguous\n",
    "        \n",
    "    #     Return both the original question and your enhanced search query.\"\"\"\n",
    "        \n",
    "    # prompt = ChatPromptTemplate.from_messages([\n",
    "    #         (\"system\", system),\n",
    "    #         (\"human\", \"Original question: {question}\\n\\nThink about what this question is really asking. What key concepts should I search for? What might the user be implying?\")\n",
    "    #     ]) \n",
    "\n",
    "    # qur_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "        for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "    re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    qur_chain = re_write_prompt | llm | StrOutputParser()\n",
    "\n",
    "    rephrased_question = qur_chain.invoke({\"question\": question})\n",
    "    \n",
    "    return {\"question\": rephrased_question}\n",
    "\n",
    "#edge\n",
    "\n",
    "def decide_generation(state):\n",
    "    \"\"\"\n",
    "    Decide whether to generate an answer based on the graded documents.\n",
    "    \"\"\"\n",
    "    print(\"---Deciding whether to generate an answer---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    if len(documents) < 1:\n",
    "        print(\"--no relevant document found or less context found, rephrasing the question--\")\n",
    "        return \"question_understanding_and_rephrasing\"\n",
    "    else:\n",
    "         print(\"--relevant documents found, generating the answer--\")\n",
    "         return \"generate\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the graph\n",
    "graphB = StateGraph(GraphState)\n",
    "# graph.add_node(START, \"retrieve\")\n",
    "graphB.add_node(\"retrieve\", retrieve)\n",
    "graphB.add_node(\"generate\", generate)\n",
    "graphB.add_node(\"grade_documents\", grade_documents)\n",
    "graphB.add_node(\"question_understanding_and_rephrasing\", question_understanding_and_rephrasing)\n",
    "\n",
    "# # Add edges (transitions)\n",
    "graphB.add_edge(START, \"retrieve\")\n",
    "# graph.add_edge(\"retrieve\", \"generate\")\n",
    "graphB.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graphB.add_conditional_edges(\"grade_documents\", decide_generation, \n",
    "                            {\n",
    "                                \"generate\": \"generate\",\n",
    "                                \"question_understanding_and_rephrasing\": \"question_understanding_and_rephrasing\"\n",
    "                            })\n",
    "graphB.add_edge(\"question_understanding_and_rephrasing\", \"retrieve\")\n",
    "# graph.add_edge(\"question_understanding_and_rephrasing\", \"grade_documents\")\n",
    "\n",
    "\n",
    "graphB.add_edge(\"generate\", END)\n",
    "\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "graph_runnableB = graphB.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_runnableB.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "--relevant documents found, generating the answer--\n",
      "---Generating answer---\n",
      "Question: Why does Harry accuse Remus Lupin of being a coward?\n",
      "Generated Answer: Harry accuses Remus Lupin of being a coward because he believes Lupin is abandoning his child for the sake of adventure, contrasting it with his father's sacrifice.\n",
      "\n",
      "---\n",
      "\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "--no relevant document found or less context found, rephrasing the question--\n",
      "---Understanding and rephrasing question---\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "--no relevant document found or less context found, rephrasing the question--\n",
      "---Understanding and rephrasing question---\n",
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='no'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1036\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://d-ais-eus-ais-chatbots.openai.azure.com/openai/deployments/gpt-4o-mini-test/chat/completions?api-version=2024-05-01-preview'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[32m      2\u001b[39m     initial_state = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     final_state = \u001b[43mgraph_runnableB\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m final_state[\u001b[33m\"\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo answer generated for question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1961\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   1959\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1960\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m1961\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1962\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1967\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1970\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1664\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   1666\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1667\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1668\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   1669\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1670\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1677\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    229\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    458\u001b[39m config = patch_config(\n\u001b[32m    459\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    460\u001b[39m )\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mgrade_documents\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     53\u001b[39m graded_docs = []\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# print(\"i am hereee\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     result = \u001b[43mretrieval_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[32m     58\u001b[39m     grade = result.binary_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3020\u001b[39m             \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3021\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3022\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3024\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5347\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5348\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5349\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5350\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5351\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5353\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5354\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    277\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    281\u001b[39m     **kwargs: Any,\n\u001b[32m    282\u001b[39m ) -> BaseMessage:\n\u001b[32m    283\u001b[39m     config = ensure_config(config)\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    285\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    780\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    642\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    644\u001b[39m flattened_outputs = [\n\u001b[32m    645\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    647\u001b[39m ]\n\u001b[32m    648\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m         )\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    641\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    850\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    855\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:781\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:929\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    888\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    926\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    927\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    928\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1276\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1264\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1271\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1272\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1273\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1274\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_base_client.py:949\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1042\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1041\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1089\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1085\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1092\u001b[39m     options=options,\n\u001b[32m   1093\u001b[39m     cast_to=cast_to,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1097\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    initial_state = {\"question\": question}\n",
    "    final_state = graph_runnableB.invoke(initial_state)\n",
    "    if final_state[\"generation\"] is None:\n",
    "        print(f\"No answer generated for question: {question}\")\n",
    "        continue\n",
    "    else:\n",
    "        # Print results\n",
    "        print(\"Question:\", final_state[\"question\"])\n",
    "        print(\"Generated Answer:\", final_state[\"generation\"])\n",
    "    # print(\"Retrieved Documents:\", final_state[\"documents\"])\n",
    "    # print(\"Original Question:\", final_state[\"question\"])\n",
    "    # print(\"Document Scores:\", final_state[\"scores\"])\n",
    "    print(\"\\n---\\n\")\n",
    "# Run the graph\n",
    "# initial_state = {\"question\": \"advice for an child having heart attack\"}\n",
    "# final_state = graph_runnableB.invoke(initial_state)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Generated Answer:\", final_state[\"generation\"])\n",
    "# print(\"Retrieved Documents:\", final_state[\"documents\"])\n",
    "# print(\"Original Question:\", final_state[\"question\"])\n",
    "# rephrased question\n",
    "# print(\"Rephrased Question:\", final_state[\"question\"])\n",
    "# print(\"Document Scores:\", final_state[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Answer grader node\n",
    "\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def answer_grader(state):\n",
    "    \"\"\"Node for grading the quality and accuracy of generated answers.\"\"\"\n",
    "    print(\"---Grading the answer---\")\n",
    "    question = state[\"question\"]\n",
    "    generation = state[\"generation\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Comprehensive system prompt for answer evaluation\n",
    "    system = \"\"\"You are an expert evaluator assessing the quality of AI-generated answers.\n",
    "    \n",
    "    You will be given:\n",
    "    1. The original user question\n",
    "    2. The retrieved context documents used to answer the question\n",
    "    3. The generated answer\n",
    "    \n",
    "    Your task is to evaluate whether the answer meets ALL of the following criteria:\n",
    "    - ACCURACY: The answer contains ONLY information that is supported by the provided context documents\n",
    "    - COMPLETENESS: The answer addresses the main aspects of the user's question\n",
    "    - RELEVANCE: The answer stays focused on what was asked and doesn't include unnecessary information\n",
    "    - TRUTHFULNESS: The answer doesn't contain any hallucinations (made-up information not in the documents)\n",
    "    - COHERENCE: The answer is well-structured, logical, and easy to understand\n",
    "    \n",
    "    Return a binary judgment:\n",
    "    - \"yes\" if the answer meets all criteria above\n",
    "    - \"no\" if the answer fails on any criterion, especially if it contains hallucinations\n",
    "    \n",
    "    IMPORTANT: Be strict about hallucinations. If the answer contains ANY information not supported by the documents, grade it \"no\".\n",
    "        \"\"\"\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\\n\\n Set of facts/retrieved documents {documents}\\n\\n Generated Answer: {generation}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "    answer_grader_chain = grade_prompt | structured_llm_grader\n",
    "    result = answer_grader_chain.invoke({\"question\": question, \"generation\": generation, \"documents\": documents})\n",
    "\n",
    "    return result.binary_score\n",
    "\n",
    "    # if result.binary_score == \"yes\":\n",
    "    #     print(\"--Answer is accurate, complete, relevant, truthful, and coherent.--\")\n",
    "    #     return {\"answer_grade\": \"yes\"} \n",
    "    # else:\n",
    "    #     print(\"--Answer is inaccurate, incomplete, irrelevant, untruthful, or incoherent. Retrying with paraphrasing.--\")\n",
    "    #     return {\"answer_grade\": \"no\"}\n",
    "    \n",
    "# edge\n",
    "def decide_final_answer(state):\n",
    "    \"\"\"\n",
    "    Decide whether to use the generated answer or regenerate.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print(\"---Deciding on final answer---\")\n",
    "\n",
    "    answer_grade =  answer_grader(state)\n",
    "\n",
    "    if answer_grade == \"yes\":\n",
    "        print(\"--Answer is accurate, complete, relevant, truthful, and coherent.--\")\n",
    "        return \"useful\"\n",
    "    else:\n",
    "        print(\"--Answer is inaccurate, incomplete, irrelevant, untruthful, or incoherent. Retrying with paraphrasing.--\")\n",
    "        return \"question_understanding_and_rephrasing\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the graph\n",
    "graphC = StateGraph(GraphState)\n",
    "# graph.add_node(START, \"retrieve\")\n",
    "graphC.add_node(\"retrieve\", retrieve)\n",
    "graphC.add_node(\"generate\", generate)\n",
    "graphC.add_node(\"grade_documents\", grade_documents)\n",
    "graphC.add_node(\"question_understanding_and_rephrasing\", question_understanding_and_rephrasing)\n",
    "\n",
    "# # Add edges (transitions)\n",
    "graphC.add_edge(START, \"retrieve\")\n",
    "# graph.add_edge(\"retrieve\", \"generate\")\n",
    "graphC.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graphC.add_conditional_edges(\"grade_documents\", decide_generation, \n",
    "                            {\n",
    "                                \"generate\": \"generate\",\n",
    "                                \"question_understanding_and_rephrasing\": \"question_understanding_and_rephrasing\"\n",
    "                            })\n",
    "graphC.add_edge(\"question_understanding_and_rephrasing\", \"retrieve\")\n",
    "graphC.add_conditional_edges(\"generate\", decide_final_answer,\n",
    "                            {\n",
    "                                \"useful\": END,\n",
    "                                \"question_understanding_and_rephrasing\": \"question_understanding_and_rephrasing\"\n",
    "                            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graphC.add_edge(\"generate\", END)\n",
    "\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "graph_runnableC = graphC.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_runnableC.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO-DO: Stop the loop after two iterations\n",
    "- probably add iter_count to state and check important nodes that they dont exceed more than 2\n",
    "- or create a consitional edge to keep tract of all the loops\n",
    "- or combine both:\n",
    "\n",
    "<!-- class GraphState(TypedDict):\n",
    "    question: str\n",
    "    iterations: int\n",
    "\n",
    "def retrieve(state: GraphState):\n",
    "        # Retrieval logic here\n",
    "        return {\"iterations\": state[\"iterations\"] + 1}\n",
    "\n",
    "def route_to_next_step(state: GraphState):\n",
    "        # Check if we should continue or end\n",
    "        if state[\"iterations\"] >= 2:\n",
    "            return END\n",
    "        return \"grade_documents\"\n",
    "\n",
    "Add conditional edge to control iterations\n",
    "    workflow.add_conditional_edges(\n",
    "        \"generate\", \n",
    "        route_to_next_step\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Retrieving documents---\n",
      "---Grading documents---\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "---Deciding whether to generate an answer---\n",
      "--relevant documents found, generating the answer--\n",
      "---Generating answer---\n",
      "---Deciding on final answer---\n",
      "---Grading the answer---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1354: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Answer is accurate, complete, relevant, truthful, and coherent.--\n",
      "Generated Answer: The main components of Asynchronous one-step Q-learning include the use of multiple parallel actor-learners to explore different parts of the environment, which helps reduce correlations in updates. It employs a target network to stabilize learning by holding it fixed for several updates before refreshing it with current weights. Additionally, the algorithm does not rely on experience replay, allowing for on-policy reinforcement learning methods to be used effectively.\n",
      "Retrieved Documents: [{'document': Document(id='92fcbf0e-f758-4025-89cc-94564b39e34b', metadata={'page': 6, 'source': 'papers\\\\1602.01783v1.pdf'}, page_content='speciﬁc target networks instead of using a single shared target network as in Algorithm 1.\\nAnother choice is which network is used for selecting actions, the model network with\\nparameters θ or the target network with parameters θ−. However, we found that these\\nmodiﬁcation led to slightly worse results on a subset of games on the Atari domain.\\n4.2 Asynchronous one-step Sarsa\\nThe asynchronous one-step Sarsa algorithm is the same as asynchronous one-step Q-learning\\nas given in Algorithm 1 except that it uses a diﬀerent target value for Q(s,a). The target\\nvalue used by one-step Sarsa is\\ny=\\n{ r for terminal s′\\nr+ γQ(s′,a′; θ−) for non-terminal s′ (6)\\nwhere a′ is the action taken in state s′ [Sutton and Barto, 1998]. We again use a target\\nnetwork and updates accumulated over multiple timesteps to stabilize learning.\\n4.3 Asynchronous n-step Q-learning\\nPseudocode for our variant of multi-step Q-learning is shown in Algorithm 2. The algorithm\\nis somewhat unusual because it operates in the forward view by explicitly computing n-step\\nreturns, as opposed to the more common backward view used by techniques like eligibility\\ntraces [Sutton and Barto, 1998]. We found that using the forward view is easier when\\ntraining neural networks with momentum-based methods and backpropagation through\\ntime. In order to compute a single update, the algorithm ﬁrst selects actions using its\\nexploration policy for up to tmax steps or until a terminal state is reached. This process\\nresults in the agent receiving up to tmax rewards from the environment since its last update.\\nThe algorithm then computes gradients for n-step Q-learning updates for each of the state-\\naction pairs encountered since the last update. Each n-step update uses the longest possible\\nn-step return resulting in a one-step update for the last state, a two-step update for the\\nsecond last state, and so on for a total of up to tmax updates. The accumulated updates\\nare then applied in a single gradient step.\\n4.4 Asynchronous advantage actor-critic\\nOur asynchronous variant of actor-critic is presented in Algorithm 3. The algorithm, which\\nwe call asynchronous advantage actor-critic (A3C), maintains a policy π(at|st; θ) and an\\nestimate of the value function V(st; θv). Like our variant of n-step Q-learning, our variant\\nof actor-critic also operates in the forward view and uses the same mix of n-step returns\\nto update both the policy and the value-function. The policy and the value function are\\nupdated after every tmax actions or when a terminal state is reached. The update performed\\nby the algorithm can be seen as ∇θ′ log π(at|st; θ′)A(st,at; θ,θv) where A(st,at; θ,θv) is an\\nestimate of the advantage function given by ∑k−1\\ni=0 γirt+i+ γkV(st+k; θv) −V(st; θv), where\\nk varies from state to state and is upper-bounded by tmax.\\nAs with the value-based methods we rely on parallel actor-learners and accumulated\\nupdates for improving training stability. Note that while the parameters θof the policy and\\nθv of the value function are shown as being separate for generality, we always share some\\n7'), 'grade': GradeDocuments(binary_score='yes')}, {'document': Document(id='72037317-71aa-4292-bbd7-c39c2daaf7f6', metadata={'page': 4, 'source': 'papers\\\\1602.01783v1.pdf'}, page_content='making the training data less non-stationary. Second, the network used for computing\\nQ-learning targets was held ﬁxed for intervals of several thousand updates, after which\\nit would be updated with the current weights of Q(s,a; θ). This technique of employing\\na target network reduces the correlations between the target and the predicted Q-values,\\nagain making the training problem less non-stationary. The loss function minimized by\\nDQN then takes the form\\nL(θ) = Es,a,r,s′∼D\\n(\\nr+ γmax\\na′\\nQ(s′,a′; θ−) −Q(s,a; θ)\\n)2\\n, (5)\\nwhere Dis the experience replay memory and θ−are the parameters of the target network.\\nBoth experience replay and the target network were empirically shown to be important for\\nobtaining the best policies on a number of Atari games, but as discussed earlier, the replay\\nmemory can have substantial memory requirements.\\n4 Asynchronous Lock-Free Reinforcement Learning\\nWe now present multi-threaded asynchronous variants of one-step Sarsa, one-step Q-learning,\\nn-step Q-learning, and advantage actor-critic. The aim in designing these methods was to\\nﬁnd RL algorithms that can train deep neural network policies reliably and without large\\nresource requirements. While the underlying RL methods are quite diﬀerent, with actor-\\ncritic being an on-policy policy search method and Q-learning being an oﬀ-policy value-\\nbased method, we use two main ideas to make all four algorithms practical given our design\\ngoal.\\nFirst, we use asynchronous actor-learners as proposed in the Gorila framework [Nair\\net al., 2015], but instead of using separate machines and a parameter server, we use mul-\\ntiple threads on a single machine. Keeping the learners on a single machine removes the\\ncommunication costs incurred by sending gradients and parameters and enables us to use\\nHogwild! [Recht et al., 2011] style updates for training the controllers.\\nSecond, we make the observation that multiple actors-learners running in parallel are\\nlikely to be exploring diﬀerent parts of the environment. Moreover, one can explicitly use\\ndiﬀerent exploration policies in each actor-learner to maximize this diversity. By running\\ndiﬀerent exploration policies in diﬀerent threads, the overall changes being made to the\\nparameters by multiple actor-learners applying online updates in parallel are likely to be\\nless correlated in time than a single agent applying online updates. Hence, we do not\\nuse a replay memory and rely on parallel actors employing diﬀerent exploration policies to\\nperform the stabilizing role undertaken by experience replay in the DQN training algorithm.\\nIn addition to stabilizing learning, using multiple parallel actor-learners has multiple\\npractical beneﬁts. First, we obtain a reduction in training time that is roughly linear in\\nthe number of parallel actor-learners. Second, since we no longer rely on experience replay\\nfor stabilizing learning we are able to use on-policy reinforcement learning methods such\\nas Sarsa and actor-critic to train neural networks in a stable way. We now describe our\\nvariants of one-step Q-learning, one-step Sarsa, n-step Q-learning and advantage actor-\\ncritic, discussing design choices speciﬁc to each algorithm.\\n5'), 'grade': GradeDocuments(binary_score='yes')}]\n",
      "Original Question: what are the main components Asynchronous one-step Q-learning \n"
     ]
    }
   ],
   "source": [
    "# Run the graph\n",
    "initial_state = {\"question\": \"what are the main components Asynchronous one-step Q-learning \"}\n",
    "final_state = graph_runnableC.invoke(initial_state)\n",
    "\n",
    "# Print results\n",
    "print(\"Generated Answer:\", final_state[\"generation\"])\n",
    "print(\"Retrieved Documents:\", final_state[\"documents\"])\n",
    "print(\"Original Question:\", final_state[\"question\"])\n",
    "# rephrased question\n",
    "# print(\"Rephrased Question:\", final_state[\"question\"])\n",
    "# print(\"Document Scores:\", final_state[\"scores\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

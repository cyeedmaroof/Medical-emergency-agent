{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a032fc",
   "metadata": {},
   "source": [
    "#### Test for connecting llamaindex retrivel outputs with langgraph DAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38104e45",
   "metadata": {},
   "source": [
    "Define llamaindex models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import get_llamaindex_model, get_llamaindex_model_mini, get_huggingface_embedding_model\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = get_llamaindex_model_mini()\n",
    "\n",
    "llm2 = get_llamaindex_model()\n",
    "\n",
    "embed_model = get_huggingface_embedding_model()\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24826055",
   "metadata": {},
   "source": [
    "define parser, vectorstore and kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42134132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 945 nodes.\n",
      "First node text: ## criteria\n",
      "- critical | unconscious adult, not breathing normally\n"
     ]
    }
   ],
   "source": [
    "from src.parser import markdownParser\n",
    "nodes = markdownParser(input_dir=\"../kgdata/\")\n",
    "print(f\"Processed {len(nodes)} nodes.\")\n",
    "if nodes:\n",
    "    print(\"First node text:\", nodes[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "423b9c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file_path: c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md\\nfile_name: 01.md\\nfile_size: 8702\\ncreation_date: 2025-04-21\\nlast_modified_date: 2025-04-21\\nheader_path: /01 Unconscious adult â€“ not breathing normally/CRITERIA\\n\\n## criteria\\n- critical | unconscious adult, not breathing normally'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].get_content(\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d21a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores 100 the nodes in a vector store\n",
    "from src import create_faiss_vector_store_and_context\n",
    "from llama_index.core import  VectorStoreIndex\n",
    "\n",
    "vector_store, storage_context = create_faiss_vector_store_and_context(nodes[:100])\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading persisted knowledge graph from ./kg_index_storage_v1/pg_store_v2_custom.json\n",
      "âœ… Successfully loaded persisted knowledge graph!\n"
     ]
    }
   ],
   "source": [
    "from src.dynamicKG_builder import knowledge_graph_construction\n",
    "import asyncio\n",
    "\n",
    "# nodes = nodes  # Use a subset for testing, adjust as needed\n",
    "# if not nodes:\n",
    "#     print(\"No nodes available for testing. Please ensure you have loaded your data correctly.\")\n",
    "# Run the test\n",
    "kg_index = asyncio.run(knowledge_graph_construction( extractor=\"Custom\", load_persist=\"./kg_index_storage_v1/pg_store_v2_custom.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index.storage_context.persist(persist_dir=\"final_structure\\kg_index_storage_v1\\pg_store_v2_custom.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"An alternative approach to specifying the depth for a knowledge graph retriever is to use metadata filtering or recursive retrieval techniques to dynamically control the depth based on query requirements. This provides more flexibility compared to static depth settings.\n",
    "\n",
    "Alternative Suggestion: Use Recursive Retrieval\n",
    "Instead of setting a fixed depth, you can use recursive retrieval techniques to dynamically explore the graph based on the query. For example:\n",
    "\n",
    "python\n",
    "\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    graph_store=graph_store,\n",
    "    max_depth=2,  # Maximum depth for recursive retrieval\n",
    "    similarity_top_k=5  # Number of nodes to retrieve at each level\n",
    ")\n",
    "nodes = recursive_retriever.retrieve(\"Your query text here\")\n",
    "for node in nodes:\n",
    "    print(node.text)\n",
    "This approach allows the retriever to explore the graph recursively, fetching nodes and their relationships up to the specified depth.\n",
    "\n",
    "Alternative Suggestion: Use Metadata Filtering\n",
    "If your graph nodes have metadata indicating their depth or relationships, you can use metadata filters to control the retrieval depth dynamically:\n",
    "\n",
    "python\n",
    "\n",
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters\n",
    "filters = MetadataFilters(filters=[\n",
    "    MetadataFilter(key=\"depth\", operator=\"LE\", value=2)  # Retrieve nodes with depth <= 2\n",
    "])\n",
    "retriever = graph_store.as_retriever(filters=filters)\n",
    "nodes = retriever.retrieve(\"Your query text here\")\n",
    "for node in nodes:\n",
    "    print(node.text)\n",
    "This approach is particularly useful if your graph is annotated with metadata that specifies the depth or other hierarchical information.\n",
    "\n",
    "Tradeoffs\n",
    "Recursive Retrieval: Provides dynamic control over depth but may introduce additional computational overhead.\n",
    "Metadata Filtering: Offers precise control based on node attributes but requires well-structured metadata in the graph.\n",
    "\"\"\"\n",
    "# Example of using the knowledge graph index to retrieve nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b93e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## can use them independently or use QueryFusionRetriever to combine results\n",
    "\n",
    "\n",
    "# vector_retriever = vector_index.as_retriever(similarity_top_k=10)\n",
    "kg_retriever = kg_index.as_retriever(retriever_mode=\"embedding\",include_text=True, similarity_top_k=10, response_mode=\"compact\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f5e86de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Results:\n",
      "\n",
      "Knowledge Graph Results:19 nodes retrieved\n",
      "Node ID: 0507dbba-58c6-445f-bdcc-07203456c566\n",
      "Text: Here are some facts extracted from the provided text:  Tidlig\n",
      "HLR -> provides -> Veiledning We -> provides -> Instructions  ##\n",
      "tidlig hlr tidlig hlr kan redde liv, men mange er usikre pÃƒÂ¥ hvordan\n",
      "det skal gjÃƒÂ¸res og redde for skade. vi vil derfor gi instruksjoner,\n",
      "veiledning og oppmuntring til alle innringere. innringere som vet\n",
      "hvordan de kan b...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: a96384ea-843a-48fe-9ebf-9ddbc1abdae2\n",
      "Text: Here are some facts extracted from the provided text:  Hypoksi\n",
      "-> prevents -> normal pusting  ## sirkulasjonsstans hos barn\n",
      "sirkulasjonsstans hos barn skyldes langt oftere hypoksi enn akutt\n",
      "hjertesykdom. derfor bÃƒÂ¸r du alltid instruere i bÃƒÂ¥de innblÃƒÂ¥singer og\n",
      "brystkompresjoner. hvis du er usikker pÃƒÂ¥ om barnet puster normalt,\n",
      "start med ÃƒÂ¥ sikre...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: c926eeb1-1339-41c5-8659-57310ad82361\n",
      "Text: Here are some facts extracted from the provided text:  hand ->\n",
      "positioned_on -> forehead  ### if yes - lie the child on his / her\n",
      "back on the floor. - tilt the head back slightly. put one hand on the\n",
      "childÃ¢â‚¬â„¢s forehead and lift the chin up. - pinch the nose and give 5\n",
      "breaths through the childÃ¢â‚¬â„¢s mouth. - check if the chest rises with\n",
      "each breath.\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 05e4aa46-7e2e-47eb-9f40-f19e0b0dfe2b\n",
      "Text: Here are some facts extracted from the provided text:  Neonatal\n",
      "resuscitation -> requires -> ventilation with mouth-to-mouth/nose\n",
      "Neonatal resuscitation -> includes -> starting ventilation One in a\n",
      "thousand -> indicates_need_for -> Combination of ventilation and chest\n",
      "compressions Neonatal resuscitation -> prevents -> death or severe\n",
      "morbidity  ...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 67a6dc04-54d1-47f0-9fde-d830f0a8285f\n",
      "Text: Here are some facts extracted from the provided text:  Emergency\n",
      "Response -> uses -> Chest Compression  ### scenario - if / when an aed\n",
      "is at hand:\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 94d8eb9d-0e1f-4f62-a763-8fd18fabda9e\n",
      "Text: Here are some facts extracted from the provided text:  Effective\n",
      "breaths -> indicates -> Successful CPR Caller -> knows -> To call 113\n",
      "## keep motivating and guiding the caller - count aloud with me: 1, 2,\n",
      "3, 4, 5 ... 28, 29, 30. - keep going, you are doing really well. -\n",
      "does the chest rise when you give breaths? - keep going until the\n",
      "medics ...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 301cbbd5-789a-49c5-bf51-54cfd943813a\n",
      "Text: Here are some facts extracted from the provided text:  lift the\n",
      "chin up -> assists_with -> chin blow gently -> administers ->\n",
      "ventilation breaths put your lips over the infantÃ¢â‚¬â„¢s mouth and nose\n",
      "-> applies_to -> mouth and nose straighten the neck -> prevents ->\n",
      "airway obstruction  ### if yes - lie the infant down on a firm\n",
      "surface. - place one h...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 1e324642-76ff-45c0-9af4-7905cb6528d8\n",
      "Text: Here are some facts extracted from the provided text:  fetch the\n",
      "defibrillator -> performed_by -> bystander defibrillator -> triggers\n",
      "-> take your hands off the person  ### if yes - if there is a\n",
      "defibrillator at hand, get someone else to fetch it. - follow the\n",
      "instructions Ã¢â‚¬â€œ the defibrillator will tell you what to do. -\n",
      "continue pushing the c...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: e6432a66-0502-433d-83a5-0f8fc6e3546b\n",
      "Text: Here are some facts extracted from the provided text:  emergency\n",
      "protocol -> activates -> cardiopulmonary resuscitation  ## criteria -\n",
      "critical | unconscious child over 1 year, not breathing normally -\n",
      "critical | unconscious infant (under 1 year), not breathing normally -\n",
      "critical | unconscious newborn, not breathing normally\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: dca48785-1486-4833-8673-9361a7dd1625\n",
      "Text: Here are some facts extracted from the provided text:  Early\n",
      "Warning -> uses -> Phone from Operations Center Identify Agonal\n",
      "Breathing Early -> prevents -> Delay in Recognizing Cardiac Arrest  ##\n",
      "tidlig varsling tidlig varsling er avhengig av at innringer erkjenner\n",
      "at situasjonen er alvorlig og vet at de skal ringe 113. hvis vi fÃƒÂ¥r\n",
      "satt over te...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: f536f4bb-7bc1-4f1c-b87b-5553acf793bc\n",
      "Text: Here are some facts extracted from the provided text:  Chest\n",
      "compression -> treats -> Unconscious adult  ## how to give good\n",
      "compressions:  - push down hard and deep, straight elbows, use your\n",
      "body weight. - push down about 5 cms. at the rate of 100 per minute,\n",
      "release completely between each compression. - count aloud with me: 1,\n",
      "2, 3, 4, 5 ......\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: e231b3bf-f105-4c9b-a49e-46139aaab1f2\n",
      "Text: Here are some facts extracted from the provided text:  Overdose\n",
      "-> causes -> Unconsciousness  ### scenario - drowning, overdose,\n",
      "hanging or other reasons related to breathing. - is the person\n",
      "drowning?\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 5a50c960-3c9a-44e4-ae41-97a38261485e\n",
      "Text: Here are some facts extracted from the provided text:\n",
      "Healthcare Facility -> equipped_with -> CPR Equipment Administer\n",
      "epinephrine -> administers -> Epinephrine injection  ### scenario -\n",
      "resuscitating an infant (under 1 yr)\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 0b9ff4a3-e816-4b94-b8b5-e14163d9a8de\n",
      "Text: Here are some facts extracted from the provided text:  place\n",
      "hands in the middle of chest -> positioned_on -> middle of chest  ###\n",
      "if yes - push down at this rate 30 times. - now give rescue breaths. -\n",
      "tilt the head back with one hand on the forehead. - lift the chin up\n",
      "with the other hand. - pinch the nose and give 2 gentle rescue\n",
      "breaths. - co...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 02a687eb-ccf9-483b-ad20-94e716132b7d\n",
      "Text: Here are some facts extracted from the provided text:  watch the\n",
      "person all the time -> facilitates -> continuous observation  ###\n",
      "advice 1. important information to the caller Ã¢â‚¬â€œ help is on the way.\n",
      "i may need to phone you back, so keep this phone free until the medics\n",
      "arrive. Ã¢â‚¬â€œ watch the person all the time. tell me immediately if\n",
      "anything ...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 29ed272d-452f-469b-8d46-e8b58201117c\n",
      "Text: Here are some facts extracted from the provided text:  Responder\n",
      "-> LOCATES_PERSON -> on Floor on Back  ### scenario - give chest\n",
      "compression to an infant (under 1 yr)\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 862c1e96-597e-42f8-aa71-6f99f3d4f191\n",
      "Text: Here are some facts extracted from the provided text:  ROSC ->\n",
      "facilitates -> diagnosis and treatment of ischemic heart disease  ##\n",
      "etter rosc etter rosc er det viktig at pas. kan komme til et sykehus\n",
      "med mulighet for utredning og behandling av iskemisk hjertesykdom.\n",
      "pasientene kan vÃƒÂ¦re svÃƒÂ¦rt ustabile og anestesilegeassistanse\n",
      "og/eller transpo...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: 885a4ecc-510d-4a97-9176-7a8b38a9ba48\n",
      "Text: Here are some facts extracted from the provided text:\n",
      "Hjertestarterregisteret -> uses -> Defibrillator (Hjertestarter)  ##\n",
      "tidlig defibrillering tidlig defibrillering er viktig for den\n",
      "fjerdedelen av pasientene som har en sjokkbar rytme, men vi kan ikke\n",
      "vite hvem det er fÃƒÂ¸r det er koblet til en defibrillator. derfor skal\n",
      "vi prÃƒÂ¸ve ÃƒÂ¥ fÃƒÂ¥ en de...\n",
      "Score:  0.000\n",
      "\n",
      "Node ID: c543fc90-6975-4862-8920-e1d8ecbc7515\n",
      "Text: Here are some facts extracted from the provided text:  bcpr ->\n",
      "positioned_on -> patient's chest  ### scenario - overdose, hanging or\n",
      "other reasons related to breathing. - unconscious adult, not breathing\n",
      "normally - bcpr (cardio pulmonary resuscitation) - am i (rescuer)\n",
      "trained in cpr?\n",
      "Score:  0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector_results = vector_retriever.retrieve(\"help me revive a unconcious person\")\n",
    "kg_results = kg_retriever.retrieve(\"help me revive a unconcious person\")\n",
    "print(\"Vector Store Results:\")\n",
    "# for node in vector_results:\n",
    "#     print(node.text)\n",
    "print(f\"\\nKnowledge Graph Results:{len(kg_results)} nodes retrieved\")\n",
    "for node in kg_results:\n",
    "    print(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdcf1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in nodes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f1028f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "# Set up recursive retriever\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c092ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrnodes = retriever_chunk.retrieve(\n",
    "    \"help me revive an unconcious person\"\n",
    ")\n",
    "for node in rrnodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7250122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "\n",
    "vector_retriever = VectorContextRetriever(\n",
    "    kg_index.property_graph_store,\n",
    "    # only needed when the graph store doesn't support vector queries\n",
    "    vector_store=kg_index.vector_store,\n",
    "    \n",
    "    # include source chunk text with retrieved paths\n",
    "    include_text=True,\n",
    "    # the number of nodes to fetch\n",
    "    similarity_top_k=10,\n",
    "    # the depth of relations to follow after node retrieval\n",
    "    path_depth=2,\n",
    "    # can provide any other kwargs for the VectorStoreQuery class\n",
    "    \n",
    ")\n",
    "\n",
    "kgretriever = kg_index.as_retriever(sub_retrievers=[vector_retriever])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c32fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgr = kgretriever.retrieve(\n",
    "    \"help me revive an unconcious person\"\n",
    ")\n",
    "print(len(kgr), \"nodes retrieved from knowledge graph retriever\")\n",
    "for node in kgr:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d334050",
   "metadata": {},
   "source": [
    "#### this is cool and all but focus on connecting lg and li (from self_eval.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fdcfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_azure_openai_model, get_azure_openai_chat_model, get_azure_openai_mini_model\n",
    "\n",
    "model = get_azure_openai_chat_model()\n",
    "model_mini = get_azure_openai_mini_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa251625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1354: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "caller -> watches -> unconscious person\n",
      "medics -> arrives -> unconscious person\n",
      "\n",
      "### advice 1. important information to the caller\n",
      "- help is on the way. i may need to phone you back, so keep this phone free until the medics arrive.\n",
      "- watch the person all the time. let me know immediately if anything changes.\n",
      "Grader response: binary_score='no'\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "monitoring -> requires -> unconscious person\n",
      "monitoring -> applies_to -> unconscious person\n",
      "\n",
      "### if yes\n",
      "- help the person to find a comfortable position.\n",
      "- keep an eye on (monitor) him / her continuously.\n",
      "- help is on the way.\n",
      "- call back immediately if s/he deteriorates (gets worse)\n",
      "- keep in touch with the caller if necessary\n",
      "Grader response: binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "#### Grader retrieval\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = model\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.  \\n\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader #| StrOutputParser()\n",
    "question = \"how to revive an unconscious person\"\n",
    "docs = vector_retriever.retrieve(question)\n",
    "\n",
    "sample_doc = docs[:2]\n",
    "# Print the first two documents for inspection\n",
    "\n",
    "retrieval_grader.invoke({\"question\": question, \"document\": docs})\n",
    "for doc in sample_doc:\n",
    "    print(doc.text)\n",
    "    response = retrieval_grader.invoke({\"question\": question, \"document\": doc.text})\n",
    "    print(\"Grader response:\", response)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e72ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bfb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d2388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49266454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

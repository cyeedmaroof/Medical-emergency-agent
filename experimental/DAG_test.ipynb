{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newac\\OneDrive\\Desktop\\Master\\final_structure\\src\\__init__.py:16: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from .DAG_creator import build_rag_workflow\n"
     ]
    }
   ],
   "source": [
    "from src.model import get_llamaindex_model, get_llamaindex_model_mini, get_huggingface_embedding_model\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = get_llamaindex_model_mini()\n",
    "\n",
    "llm2 = get_llamaindex_model()\n",
    "\n",
    "embed_model = get_huggingface_embedding_model()\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac879481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 945 nodes.\n",
      "First node text: ## criteria\n",
      "- critical | unconscious adult, not breathing normally\n"
     ]
    }
   ],
   "source": [
    "from src.parser import markdownParser\n",
    "nodes = markdownParser(input_dir=\"../kgdata/\")\n",
    "print(f\"Processed {len(nodes)} nodes.\")\n",
    "if nodes:\n",
    "    print(\"First node text:\", nodes[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349ad474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '01.md',\n",
       " 'file_name': '01.md',\n",
       " 'file_size': 8702,\n",
       " 'creation_date': '2025-04-21',\n",
       " 'last_modified_date': '2025-04-21',\n",
       " 'header_path': '/01 Unconscious adult – not breathing normally/CRITERIA'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921aa3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfinal_structure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retriever\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m docs  = \u001b[43mcreate_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhybrid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCustom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Master\\final_structure\\src\\retriever.py:41\u001b[39m, in \u001b[36mcreate_retriever\u001b[39m\u001b[34m(question, nodes, max_nodes, type, llm, extractor, load_persist, persist_path, max_triplets_per_chunk, similarity_top_k)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03mCreate a retriever index based on the specified type.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m        tuple: (VectorStoreIndex, kg_index, vector_store, storage_context)\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_nodes:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     nodes = \u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mvector_store\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Create a FAISS vector store and storage context\u001b[39;00m\n\u001b[32m     44\u001b[39m     vector_store, storage_context = create_faiss_vector_store_and_context(nodes)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from src.retriever import create_retriever\n",
    "\n",
    "docs  = create_retriever(nodes, llm=llm, type=\"hybrid\", extractor=\"Custom\", max_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58611d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss_index = a.client  # or index.vector_store._faiss_index\n",
    "# embeddings = [faiss_index.reconstruct(i) for i in range(faiss_index.ntotal)]\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69425320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://d-ais-eus-ais-chatbots.openai.azure.com/openai/deployments/o1-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Results:\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF YES'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF YES', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF NO'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF NO', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/SITUATIONAL GUIDANCE & IMPORTANT TO ASCERTAIN'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/SITUATIONAL GUIDANCE & IMPORTANT TO ASCERTAIN', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF YES'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/IF YES', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/SCENARIO'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/SCENARIO', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/SCENARIO'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE/SCENARIO', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/EMERGENCY RESPONSE', 'source': 'vector'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally'}\n",
      "{'file_path': 'c:\\\\Users\\\\newac\\\\OneDrive\\\\Desktop\\\\Master\\\\final_structure\\\\..\\\\kgdata\\\\01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally', 'source': 'vector'}\n",
      "{'file_path': '01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/CRITERIA'}\n",
      "{'file_path': '01.md', 'file_name': '01.md', 'file_size': 8702, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21', 'header_path': '/01 Unconscious adult – not breathing normally/CRITERIA', 'source': 'vector'}\n",
      "\n",
      "Knowledge Graph Results:\n",
      "Node ID: 7a92ec4c-93b1-4178-8dcb-b48376db27fd\n",
      "Text: Here are some facts extracted from the provided text:  Providing\n",
      "guidance to all callers -> assists_with -> CPR instructions Respect\n",
      "towards caller -> requires -> respectful communication Checking\n",
      "hjertestarterregisteret -> requires -> defibrillator availability\n",
      "Airway obstruction removal -> requires -> mouth opening  ##\n",
      "situational guidance & i...\n",
      "Score:  0.696\n",
      "\n",
      "Node ID: a3054db2-e4cf-4f16-b114-37ce0bceb548\n",
      "Text: Here are some facts extracted from the provided text:  lay the\n",
      "person on the floor -> requires -> supine position push down hard ->\n",
      "requires -> straight elbows  ### if yes - push down at this rate 30\n",
      "times. - now give rescue breaths. - tilt the head back with one hand\n",
      "on the forehead. - lift the chin up with the other hand. - pinch the\n",
      "nose and ...\n",
      "Score:  0.689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector_retriever = vec_rev.as_retriever(similarity_top_k=10)\n",
    "# kg_retriever = kg_index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "# vector_results = vector_retriever.retrieve(\"help me revive a unconcious person\")\n",
    "# kg_results = kg_retriever.retrieve(\"help me revive a unconcious person\")\n",
    "# print(\"Vector Store Results:\")\n",
    "# for node in vector_results:\n",
    "#     print(node.metadata)\n",
    "#     node.metadata['source'] = 'vector'\n",
    "#     print(node.metadata)\n",
    "# print(\"\\nKnowledge Graph Results:\")\n",
    "# for node in kg_results:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.documents import Document\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be5323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETREIVER_TYPE = \"hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52bf2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_azure_openai_model, get_azure_openai_chat_model, get_azure_openai_mini_model\n",
    "\n",
    "model = get_azure_openai_chat_model()\n",
    "model_mini = get_azure_openai_mini_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b0ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import json\n",
    "from typing import List, Optional, Dict, Any\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4740da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9476b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATE DEFINITION\n",
    "# =============================================================================\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    \n",
    "    Attributes:\n",
    "        question: The original user question\n",
    "        documents: List of retrieved documents\n",
    "        generation: Generated answer\n",
    "        grade: Grade of document relevance\n",
    "        iterations: Number of iterations for rephrasing\n",
    "        rephrased_question: Rephrased version of the question\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "    grade: str\n",
    "    iterations: int\n",
    "    rephrased_question: str\n",
    "    llm: str\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TODO: Seperate the retriverals from here\n",
    "from src.retriever import create_retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e3dc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the question.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"--- RETRIEVE ---\")\n",
    "    \n",
    "    # Use rephrased question if available, otherwise use original\n",
    "    question = state.get(\"rephrased_question\", state[\"question\"])\n",
    "\n",
    "    if state.get(\"rephrased_question\"):\n",
    "        print(f\"Using rephrased question: {question}\")\n",
    "    else:\n",
    "        print(f\"Using original question: {question}\")\n",
    "    \n",
    "    # if RETREIVER_TYPE == \"hybrid\":\n",
    "    #     print(\"Using hybrid retriever\")\n",
    "    #     vec_index, kg_index, a,b =create_retriever(nodes, llm=llm, type=\"hybrid\", extractor=\"Custom\", max_nodes=10, load_persist=\"./kg_index_storage_v1/pg_store_v2_custom.json\")\n",
    "    #     vector_retriever = vec_index.as_retriever(similarity_top_k=2)\n",
    "    #     kg_retriever = kg_index.as_retriever(similarity_top_k=2)\n",
    "    #     # Retrieve documents from both vector and knowledge graph retrievers\n",
    "    #     vec_documents = vector_retriever.retrieve(question)\n",
    "    #     kg_documents = kg_retriever.retrieve(question)\n",
    "\n",
    "    #     # Adding metadata to distinguish sources\n",
    "    #     for doc in vec_documents:\n",
    "    #         doc.metadata['source'] = 'vector'\n",
    "    #     for doc in kg_documents:\n",
    "    #         doc.metadata['source'] = 'knowledge_graph'\n",
    "\n",
    "    #     documents = vec_documents + kg_documents[:2]  # Limit KG results to 10 for performance\n",
    "    #     print(f\"Retrieved {len(documents)} documents from hybrid retriever. Vector: {len(vec_documents)}, KG: {len(kg_documents)}\")\n",
    "        \n",
    "    # elif RETREIVER_TYPE == \"vector\":\n",
    "    #     print(\"Using vector retriever\")\n",
    "    #     vec_index, kg_index, a,b =create_retriever(nodes, llm=llm, type=\"vector_store\", extractor=\"Custom\", max_nodes=10)\n",
    "    #     vector_retriever = vec_index.as_retriever(similarity_top_k=10)\n",
    "    #     kg_retriever = None\n",
    "\n",
    "    #     documents = vector_retriever.retrieve(question)\n",
    "    #     for doc in documents:\n",
    "    #         doc.metadata['source'] = 'vector'\n",
    "    # elif RETREIVER_TYPE == \"kg\":\n",
    "    #     print(\"Using knowledge graph retriever\")\n",
    "    #     vec_index, kg_index, a,b =create_retriever(nodes, llm=llm, type=\"knowledge_graph\", extractor=\"Custom\", max_nodes=10, persist_path=\"final_structure\\kg_index_storage_v1\\pg_store_v2_custom.json\")\n",
    "    #     vector_retriever = None\n",
    "    #     kg_retriever = kg_index.as_retriever(similarity_top_k=10)\n",
    "\n",
    "    #     documents = kg_retriever.retrieve(question)\n",
    "    #     for doc in documents:\n",
    "    #         doc.metadata['source'] = 'knowledge_graph'\n",
    "        \n",
    "    # else:\n",
    "    #     raise ValueError(f\"Unknown retriever type: {RETREIVER_TYPE}, define global variable RETREIVER_TYPE as 'hybrid', 'vector', or 'kg'\")\n",
    "    documents = create_retriever(question, llm=model, extractor=\"Custom\", max_nodes=10, load_persist=\"./kg_index_storage_v1/pg_store_v2_custom.json\")\n",
    "    print(f\"Retrieved {len(documents)} documents\")\n",
    "    \n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": state[\"question\"],\n",
    "        \"rephrased_question\": state.get(\"rephrased_question\", \"\"),\n",
    "        \"iterations\": state.get(\"iterations\", 0),\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "        \"grade\": state.get(\"grade\", \"\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2cdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with document relevance grade\n",
    "    \"\"\"\n",
    "    print(\"--- CHECK DOCUMENT RELEVANCE TO QUESTION ---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Grading prompt\n",
    "    grade_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n",
    "        Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "    ])\n",
    "    \n",
    "    # Grade each document\n",
    "    relevant_docs = []\n",
    "    for doc in documents:\n",
    "        grade_chain = grade_prompt | model | StrOutputParser()\n",
    "        grade = grade_chain.invoke({\"question\": question, \"document\": doc.text})\n",
    "        \n",
    "        try:\n",
    "            grade_dict = json.loads(grade)\n",
    "            if grade_dict.get(\"score\", \"\").lower() == \"yes\":\n",
    "                relevant_docs.append(doc)\n",
    "                print(f\"--- GRADE: DOCUMENT RELEVANT ---\")\n",
    "            else:\n",
    "                print(f\"--- GRADE: DOCUMENT NOT RELEVANT ---\")\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, assume relevant to be safe\n",
    "            relevant_docs.append(doc)\n",
    "            print(f\"--- GRADE: DOCUMENT RELEVANT (JSON parse failed) ---\")\n",
    "    \n",
    "    # Determine overall grade\n",
    "    if relevant_docs:\n",
    "        grade = \"relevant\"\n",
    "        # documents_to_use = relevant_docs\n",
    "    else:\n",
    "        grade = \"not_relevant\"\n",
    "        # documents_to_use = documents  # Keep all documents if none are graded as relevant\n",
    "        \n",
    "    \n",
    "    return {\n",
    "        \"documents\": relevant_docs,\n",
    "        \"question\": state[\"question\"],\n",
    "        \"rephrased_question\": state.get(\"rephrased_question\", \"\"),\n",
    "        \"iterations\": state.get(\"iterations\", 0),\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "        \"grade\": grade\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34b97743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate answer using the retrieved documents.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with generated answer\n",
    "    \"\"\"\n",
    "    print(\"--- GENERATE ---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Create context from documents\n",
    "    context = \"\\n\\n\".join([doc.text for doc in documents])\n",
    "    \n",
    "    # Generation prompt\n",
    "    generate_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an assistant for question-answering tasks.\n",
    "        Use the following pieces of retrieved context to answer the question.\n",
    "        If you don't know the answer, just say that you don't know.\n",
    "        \n",
    "        Do not make up answers or provide information not present in the context.\n",
    "         \n",
    "         Say 'I don't know' if you cannot find an answer in the context.\n",
    "        If the question is not answerable with the provided context, say 'I don't know'.\n",
    "        \n",
    "        Context: {context}\"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    # Generate answer\n",
    "    generate_chain = generate_prompt | model | StrOutputParser()\n",
    "    generation = generate_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    print(f\"Generated answer: {generation[:100]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"question\": state[\"question\"],\n",
    "        \"rephrased_question\": state.get(\"rephrased_question\", \"\"),\n",
    "        \"iterations\": state.get(\"iterations\", 0),\n",
    "        \"generation\": generation,\n",
    "        \"grade\": state.get(\"grade\", \"\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ecbc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state: GraphState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question for retrieval.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with rephrased question\n",
    "    \"\"\"\n",
    "    print(\"--- TRANSFORM QUERY ---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    \n",
    "    # Query transformation prompt\n",
    "    transform_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are generating questions that are well optimized for retrieval.\n",
    "        Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "        Here is the initial question:\n",
    "        \\n ------- \\n\n",
    "        {question} \n",
    "        \\n ------- \\n\n",
    "        Formulate an improved question that will be more effective for document retrieval.\"\"\"),\n",
    "        (\"human\", \"Provide the improved question:\")\n",
    "    ])\n",
    "    \n",
    "    # Transform query\n",
    "    transform_chain = transform_prompt | model | StrOutputParser()\n",
    "    rephrased_question = transform_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"Rephrased question: {rephrased_question}\")\n",
    "    \n",
    "    return {\n",
    "        \"documents\": state.get(\"documents\", []),\n",
    "        \"question\": state[\"question\"],\n",
    "        \"rephrased_question\": rephrased_question,\n",
    "        \"iterations\": iterations + 1,\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "        \"grade\": state.get(\"grade\", \"\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ffe016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Next node to call\n",
    "    \"\"\"\n",
    "    print(\"--- CHECK HALLUCINATIONS ---\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    \n",
    "    # Hallucination grading prompt\n",
    "    hallucination_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\n",
    "        Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
    "    ])\n",
    "    \n",
    "    hallucination_chain = hallucination_prompt | model | StrOutputParser()\n",
    "    grade = hallucination_chain.invoke({\n",
    "        \"documents\": \"\\n\\n\".join([doc.text for doc in documents]),\n",
    "        \"generation\": generation\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        grade_dict = json.loads(grade)\n",
    "        grounded = grade_dict.get(\"score\", \"\").lower() == \"yes\"\n",
    "    except json.JSONDecodeError:\n",
    "        grounded = True  # Assume grounded if parsing fails\n",
    "    \n",
    "    print(f\"Grounded: {grounded}\")\n",
    "    \n",
    "    # Check question answering\n",
    "    print(\"--- GRADE GENERATION vs QUESTION ---\")\n",
    "    \n",
    "    answer_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a grader assessing whether an answer addresses / resolves a question.\n",
    "        Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the question.\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "    ])\n",
    "    \n",
    "    answer_chain = answer_prompt | model | StrOutputParser()\n",
    "    grade = answer_chain.invoke({\"question\": question, \"generation\": generation})\n",
    "    \n",
    "    try:\n",
    "        grade_dict = json.loads(grade)\n",
    "        useful = grade_dict.get(\"score\", \"\").lower() == \"yes\"\n",
    "    except json.JSONDecodeError:\n",
    "        useful = True  \n",
    "    \n",
    "    print(f\"Useful: {useful}\")\n",
    "\n",
    "    # Add safety check for max iterations\n",
    "    if iterations >= 1:\n",
    "        print(\"--- MAX ITERATIONS REACHED, ENDING ---\")\n",
    "        return END\n",
    "    \n",
    "    if grounded and useful:\n",
    "        print(\"--- DECISION: GENERATION IS GROUNDED AND USEFUL ---\")\n",
    "        return \"Useful\"  # Use END instead of \"Useful\"\n",
    "    elif not grounded:\n",
    "        print(\"--- DECISION: GENERATION IS NOT GROUNDED, RE-GENERATE ---\")\n",
    "        return \"generate\" \n",
    "    else:\n",
    "        print(\"--- DECISION: GENERATION IS NOT USEFUL, TRANSFORM QUERY ---\")\n",
    "        return \"transform_query\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0f9bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer or re-generate a question.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Next node to call\n",
    "    \"\"\"\n",
    "    print(\"--- ASSESS GRADED DOCUMENTS ---\")\n",
    "    \n",
    "    grade = state[\"grade\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    print(f\"Grade: {grade}, Number of documents: {len(documents)}\")\n",
    "    \n",
    "    # if grade == \"relevant\":\n",
    "    if len(documents) > 5:\n",
    "        print(\"--- DECISION: DOCUMENTS ARE RELEVANT, GENERATE ANSWER ---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"--- DECISION: DOCUMENTS ARE NOT RELEVANT, TRANSFORM QUERY ---\")\n",
    "        return \"transform_query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "682796b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_iterations_check(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    Check if maximum iterations reached to prevent infinite loops.\n",
    "    \n",
    "    Args:\n",
    "        state: The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        Next node to call\n",
    "    \"\"\"\n",
    "    max_iterations = 1\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    \n",
    "    if iterations >= max_iterations:\n",
    "        print(f\"--- MAX ITERATIONS ({max_iterations}) REACHED ---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"retrieve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2fb55e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the graph\n",
    "graphA = StateGraph(GraphState)\n",
    "# graph.add_node(START, \"retrieve\")\n",
    "graphA.add_node(\"retrieve\", retrieve)\n",
    "# graphA.add_node(\"generate\", generate)\n",
    "graphA.add_node(\"grade_documents\", grade_documents)\n",
    "graphA.add_node(\"generate\", generate)\n",
    "graphA.add_node(\"transform_query\", transform_query)\n",
    "\n",
    "# # Add edges (transitions)\n",
    "graphA.add_edge(START, \"retrieve\")\n",
    "graphA.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graphA.add_conditional_edges(\"grade_documents\", decide_to_generate, \n",
    "                            {\n",
    "                                \"generate\": \"generate\",\n",
    "                                \"transform_query\": \"transform_query\"\n",
    "                            })\n",
    "graphA.add_conditional_edges(\n",
    "        \"transform_query\",\n",
    "        max_iterations_check,\n",
    "        {\n",
    "            \"retrieve\": \"retrieve\",\n",
    "            \"generate\": \"generate\"\n",
    "        }\n",
    "    )\n",
    "graphA.add_conditional_edges(\n",
    "        \"generate\",\n",
    "        grade_generation_v_documents_and_question,\n",
    "        {\n",
    "            \"Useful\": END,\n",
    "            END: END,\n",
    "            \"transform_query\": \"transform_query\",\n",
    "            \"generate\": \"generate\"\n",
    "        }\n",
    "    )\n",
    "# graphA.add_edge(\"generate\", \"retrieve\")\n",
    "# graphA.add_edge(\"grade_documents\", END)\n",
    "# graphA.add_edge(\"retrieve\", \"grade_documents\")\n",
    "# graphA.add_conditional_edges(\"grade_documents\", decide_generation, \"generate\")\n",
    "# graphA.add_edge(\"generate\", END)\n",
    "\n",
    "\n",
    "# Compile the graph\n",
    "graph_runnable = graphA.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph_runnable.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d66c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVE ---\n",
      "Using original question: harry potter and the philosopher's stone summary\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mharry potter and the philosopher\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms stone summary\u001b[39m\u001b[33m\"\u001b[39m,}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Node\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1664\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   1666\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1667\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1668\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   1669\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1670\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1677\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    229\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    458\u001b[39m config = patch_config(\n\u001b[32m    459\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    460\u001b[39m )\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing original question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# if RETREIVER_TYPE == \"hybrid\":\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#     print(\"Using hybrid retriever\")\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     vec_index, kg_index, a,b =create_retriever(nodes, llm=llm, type=\"hybrid\", extractor=\"Custom\", max_nodes=10, load_persist=\"./kg_index_storage_v1/pg_store_v2_custom.json\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m#     raise ValueError(f\"Unknown retriever type: {RETREIVER_TYPE}, define global variable RETREIVER_TYPE as 'hybrid', 'vector', or 'kg'\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m documents = \u001b[43mcreate_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCustom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_persist\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./kg_index_storage_v1/pg_store_v2_custom.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     64\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m: documents,\n\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrade\u001b[39m\u001b[33m\"\u001b[39m: state.get(\u001b[33m\"\u001b[39m\u001b[33mgrade\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Master\\final_structure\\src\\retriever.py:41\u001b[39m, in \u001b[36mcreate_retriever\u001b[39m\u001b[34m(question, nodes, max_nodes, type, llm, extractor, load_persist, persist_path, max_triplets_per_chunk, similarity_top_k)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03mCreate a retriever index based on the specified type.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m        tuple: (VectorStoreIndex, kg_index, vector_store, storage_context)\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_nodes:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     nodes = \u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mvector_store\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Create a FAISS vector store and storage context\u001b[39;00m\n\u001b[32m     44\u001b[39m     vector_store, storage_context = create_faiss_vector_store_and_context(nodes)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable",
      "During task with name 'retrieve' and id '0791121d-419e-133b-d87c-b0ebbb43d534'"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"harry potter and the philosopher's stone summary\",}\n",
    "for output in graph_runnable.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "# Will be in the last node\n",
    "print(value[\"documents\"])\n",
    "print(value[\"grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1822b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85636a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVE ---\n",
      "Using original question: how to revive a person who is unconscious\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m inputs = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretriever_type\u001b[39m\u001b[33m\"\u001b[39m: RETREIVER_TYPE,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mload_persist\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m./kg_index_storage_v1/pg_store_v2_custom.json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Run the workflow\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Node\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1664\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   1666\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1667\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1668\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   1669\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1670\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1677\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:231\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    229\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:462\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    458\u001b[39m config = patch_config(\n\u001b[32m    459\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    460\u001b[39m )\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\newac\\OneDrive\\Desktop\\Master\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:226\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Master\\final_structure\\src\\DAG_creator.py:59\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing original question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m documents = \u001b[43mcreate_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mRETREIVER_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_persist\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mload_persist\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     63\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m: documents,\n\u001b[32m     64\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrade\u001b[39m\u001b[33m\"\u001b[39m: state.get(\u001b[33m\"\u001b[39m\u001b[33mgrade\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Master\\final_structure\\src\\retriever.py:78\u001b[39m, in \u001b[36mcreate_retriever\u001b[39m\u001b[34m(question, nodes, max_nodes, type, llm, extractor, load_persist, persist_path, max_triplets_per_chunk, similarity_top_k)\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m kg_docs\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mhybrid\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Create both vector store and knowledge graph index\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     vector_store, storage_context = create_faiss_vector_store_and_context(\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     79\u001b[39m     vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n\u001b[32m     81\u001b[39m     kg_index = asyncio.run(\n\u001b[32m     82\u001b[39m         knowledge_graph_construction(\n\u001b[32m     83\u001b[39m             nodes,\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m         )\n\u001b[32m     90\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable",
      "During task with name 'retrieve' and id '6bffab48-2bd1-cc27-7ded-0f9c7182ffc8'"
     ]
    }
   ],
   "source": [
    "# using the DAG\n",
    "from src.DAG_creator import build_rag_workflow\n",
    "question= \"how to revive a person who is unconscious\"\n",
    "\n",
    "app = build_rag_workflow()\n",
    "\n",
    "# Initial state\n",
    "inputs = {\n",
    "    \"question\": question,\n",
    "    \"llm\": model,\n",
    "    \"retriever_type\": RETREIVER_TYPE,\n",
    "    \"load_persist\": \"./kg_index_storage_v1/pg_store_v2_custom.json\",\n",
    "}\n",
    "\n",
    "# Run the workflow\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "# Will be in the last node\n",
    "print(value[\"documents\"])\n",
    "print(value[\"grade\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
